{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Копия блокнота \"Gender-pronoun-resolution.ipynb\"","provenance":[{"file_id":"1coEsqR7X0ZtK9Ivd36OnHC0sOoBPBiAt","timestamp":1623854596634},{"file_id":"1F5JaUSKJ_IXzVobx4LjEGYrhPI6A-I6Y","timestamp":1623695024148},{"file_id":"1c4_O25_p46FV_5dU9Zy29iEutA223Sqe","timestamp":1621590195173}],"authorship_tag":"ABX9TyOs4HCHRoBFzJf6iQ5ODo7h"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"e2jyYuFBj9CR"},"source":["# Import and loading data\n"]},{"cell_type":"code","metadata":{"id":"c0HEZybdxK7u","executionInfo":{"status":"ok","timestamp":1623836117433,"user_tz":-180,"elapsed":248,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["import numpy as np \n","import pandas as pd \n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjmiT6a4xO9u","executionInfo":{"status":"ok","timestamp":1623836122539,"user_tz":-180,"elapsed":3215,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-development.tsv -q\n","!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-test.tsv -q\n","!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-validation.tsv -q"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tXOPMAbMd_Pr","executionInfo":{"status":"ok","timestamp":1623836148627,"user_tz":-180,"elapsed":247,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"f1919d29-d388-47b7-8242-d0e41fad60eb"},"source":["device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","device = torch.device(device)\n","print(device)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiAyumvNxRYc","executionInfo":{"status":"ok","timestamp":1623836140537,"user_tz":-180,"elapsed":10846,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"6a4f8d66-f675-4555-b38e-77d7b5872637"},"source":["!pip install pytorch-pretrained-bert\n","!pip install https://github.com/ceshine/pytorch_helper_bot/archive/0.0.4.zip"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 19.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/55/e66b557bdbc266ab4f15249f382f5d7d165fee1caa7e12c96348c05ea53d/boto3-1.17.95-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 15.9MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.1+cu101)\n","Collecting botocore<1.21.0,>=1.20.95\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/70/43ebe47ab7591eca35be1dcbb0e4ede2a3cf15915ad05876920b63296988/botocore-1.20.95-py2.py3-none-any.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 15.2MB/s \n","\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.1MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.95->boto3->pytorch-pretrained-bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.95->boto3->pytorch-pretrained-bert) (1.15.0)\n","\u001b[31mERROR: botocore 1.20.95 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","Successfully installed boto3-1.17.95 botocore-1.20.95 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2\n","Collecting https://github.com/ceshine/pytorch_helper_bot/archive/0.0.4.zip\n","\u001b[?25l  Downloading https://github.com/ceshine/pytorch_helper_bot/archive/0.0.4.zip\n","\u001b[K     \\ 20kB 34.4MB/s\n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from PyTorchHelperBot==0.0.4) (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->PyTorchHelperBot==0.0.4) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->PyTorchHelperBot==0.0.4) (1.19.5)\n","Building wheels for collected packages: PyTorchHelperBot\n","  Building wheel for PyTorchHelperBot (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyTorchHelperBot: filename=PyTorchHelperBot-0.0.4-cp37-none-any.whl size=7180 sha256=fd581caac8367a1e5a3966340da78090b5bc154d5c3db386417d4b6f97ef3653\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dnjcqq5b/wheels/1f/01/01/da39a14e8e30666f3eec7106664e59059789c330a11b5fa357\n","Successfully built PyTorchHelperBot\n","Installing collected packages: PyTorchHelperBot\n","Successfully installed PyTorchHelperBot-0.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wVp-a4gWxUdJ","executionInfo":{"status":"ok","timestamp":1623836146253,"user_tz":-180,"elapsed":3873,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["import os\n","\n","# This variable is used by helperbot to make the training deterministic\n","os.environ[\"SEED\"] = \"420\"\n","\n","import logging\n","from pathlib import Path\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from pytorch_pretrained_bert import BertTokenizer\n","from pytorch_pretrained_bert.modeling import BertModel\n","\n","from helperbot import BaseBot, TriangularLR, WeightDecayOptimizerWrapper"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k9yfU4qYkIPe"},"source":["# Preparation functions"]},{"cell_type":"code","metadata":{"id":"0njedZqOxest","executionInfo":{"status":"ok","timestamp":1623850300197,"user_tz":-180,"elapsed":248,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["def insert_tag(row):\n","    \"\"\"Insert custom tags to help us find the position of A, B, and the pronoun after tokenization.\"\"\"\n","    to_be_inserted = sorted([\n","        (row[\"A-offset\"], \" [A] \"),\n","        (row[\"B-offset\"], \" [B] \"),\n","        (row[\"Pronoun-offset\"], \" [P] \")\n","    ], key=lambda x: x[0], reverse=True)\n","    text = row[\"Text\"]\n","    for offset, tag in to_be_inserted:\n","        text = text[:offset] + tag + text[offset:]\n","    return text\n","\n","def tokenize(text, tokenizer):\n","    \"\"\"Returns a list of tokens and the positions of A, B, and the pronoun.\"\"\"\n","    entries = {}\n","    final_tokens = []\n","    for token in tokenizer.tokenize(text):\n","        if token in (\"[A]\", \"[B]\", \"[P]\"):\n","            entries[token] = len(final_tokens)\n","            continue\n","        final_tokens.append(token)\n","    return final_tokens, (entries[\"[A]\"], entries[\"[B]\"], entries[\"[P]\"])\n","\n","class GAPDataset(Dataset):\n","    \"\"\"Custom GAP Dataset class\"\"\"\n","    def __init__(self, df, tokenizer, labeled=True):\n","        self.labeled = labeled\n","        if labeled:\n","            tmp = df[[\"A-coref\", \"B-coref\"]].copy()\n","            tmp[\"Neither\"] = ~(df[\"A-coref\"] | df[\"B-coref\"])\n","            self.y = tmp.values.astype(\"bool\")\n","\n","        # Extracts the tokens and offsets(positions of A, B, and P)\n","        self.offsets, self.tokens = [], []\n","        for _, row in df.iterrows():\n","            text = insert_tag(row)\n","            tokens, offsets = tokenize(text, tokenizer)\n","            self.offsets.append(offsets)\n","            self.tokens.append(tokenizer.convert_tokens_to_ids(\n","                [\"[CLS]\"] + tokens + [\"[SEP]\"]))\n","        \n","    def __len__(self):\n","        return len(self.tokens)\n","\n","    def __getitem__(self, idx):\n","        if self.labeled:\n","            return self.tokens[idx], self.offsets[idx], self.y[idx]\n","        return self.tokens[idx], self.offsets[idx]\n","    \n","def collate_examples(batch, truncate_len=500):\n","    \"\"\"Batch preparation.\n","    \n","    1. Pad the sequences\n","    2. Transform the target.\n","    \"\"\"\n","    transposed = list(zip(*batch))\n","    max_len = min(\n","        max((len(x) for x in transposed[0])),\n","        truncate_len\n","    )\n","    tokens = np.zeros((len(batch), max_len), dtype=np.int64)\n","    for i, row in enumerate(transposed[0]):\n","        row = np.array(row[:truncate_len])\n","        tokens[i, :len(row)] = row\n","    token_tensor = torch.from_numpy(tokens)\n","    # Offsets\n","    offsets = torch.stack([\n","        torch.LongTensor(x) for x in transposed[1]\n","    ], dim=0) + 1 # Account for the [CLS] token\n","    # Labels\n","    if len(transposed) == 2:\n","        return token_tensor, offsets, None\n","    one_hot_labels = torch.stack([\n","        torch.from_numpy(x.astype(\"uint8\")) for x in transposed[2]\n","    ], dim=0)\n","    _, labels = one_hot_labels.max(dim=1)\n","    return token_tensor, offsets, labels\n","\n","def collate_examples_no_labels(batch, truncate_len=500):\n","    \"\"\"Batch preparation.\n","    \n","    1. Pad the sequences\n","    2. Transform the target.\n","    \"\"\"\n","    transposed = list(zip(*batch))\n","    print(\"transposed size is\", transposed.size())\n","    max_len = min(\n","        max((len(x) for x in transposed[0])),\n","        truncate_len\n","    )\n","    tokens = np.zeros((len(batch), max_len), dtype=np.int64)\n","    for i, row in enumerate(transposed[0]):\n","        row = np.array(row[:truncate_len])\n","        tokens[i, :len(row)] = row\n","    token_tensor = torch.from_numpy(tokens)\n","    # Offsets\n","    offsets = torch.stack([\n","        torch.LongTensor(x) for x in transposed[1]\n","    ], dim=0) + 1 # Account for the [CLS] token\n","    # Labels\n","    if len(transposed) == 2:\n","        return token_tensor, offsets, None\n","    one_hot_labels = torch.stack([\n","        torch.from_numpy(x.astype(\"uint8\")) for x in transposed[2]\n","    ], dim=0)\n","    _, labels = one_hot_labels.max(dim=1)\n","    return token_tensor, offsets, labels\n"],"execution_count":155,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bETMoEtSkN3H"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"zSyhR-vCYLnq","executionInfo":{"status":"ok","timestamp":1623850303665,"user_tz":-180,"elapsed":238,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["# Classical MLP model\n","class Head(nn.Module):\n","    \"\"\"The MLP submodule\"\"\"\n","    def __init__(self, bert_hidden_size: int):\n","        super().__init__()\n","        self.head_hidden_size = 1024  # MLP hidden size\n","        self.bert_hidden_size = bert_hidden_size   # Bert hidden size\n","        self.fc = nn.Sequential(\n","            nn.BatchNorm1d(bert_hidden_size * 3),  # Batch Normalization * 3 is because the bert_output of A,B is expanded into 1 dimension\n","            nn.Dropout(0.5),                       # Random deactivation\n","            nn.Linear(bert_hidden_size * 3, self.head_hidden_size), # Linear layer\n","            nn.ReLU(),                                              # Activation function\n","            nn.BatchNorm1d(self.head_hidden_size),\n","            nn.Dropout(0.5),\n","            nn.Linear(self.head_hidden_size, self.head_hidden_size),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(self.head_hidden_size),\n","            nn.Dropout(0.5),\n","            nn.Linear(self.head_hidden_size, self.head_hidden_size),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(self.head_hidden_size),\n","            nn.Dropout(0.5),\n","            nn.Linear(self.head_hidden_size, 3)\n","        )\n","        \n","        # Parametrs inialization\n","        for i, module in enumerate(self.fc):\n","            if isinstance(module, (nn.BatchNorm1d, nn.BatchNorm2d)):\n","                nn.init.constant_(module.weight, 1)\n","                nn.init.constant_(module.bias, 0)\n","                print(\"Initing batchnorm\")\n","            elif isinstance(module, nn.Linear):\n","                if getattr(module, \"weight_v\", None) is not None:\n","                    nn.init.uniform_(module.weight_g, 0, 1)\n","                    nn.init.kaiming_normal_(module.weight_v)\n","                    print(\"Initing linear with weight normalization\")\n","                    assert model[i].weight_g is not None\n","                else:\n","                    nn.init.kaiming_normal_(module.weight)\n","                    print(\"Initing linear\")\n","                nn.init.constant_(module.bias, 0)\n","    \n","    # Forward propagation\n","    def forward(self, bert_outputs, offsets):\n","        # bert_outputs:[batch_size, seq_length, hidden_szie]\n","        assert bert_outputs.size(2) == self.bert_hidden_size   \n","        \n","        # Taking out the embeddings at the offsets of A and B\n","        # unsqueeze(2):Expand 2-dimensional offsets to 3-dimensional\n","        # Extend a dimension of size 1. Such as (2,2,1) expands to (2,2,3)\n","        # input.gather(dim,index), index the specified dimension。For example, for a 4*3 tensor,indexing dim=1,then the value of index is 0~2.\n","        extracted_outputs = bert_outputs.gather(\n","            1, offsets.unsqueeze(2).expand(-1, -1, bert_outputs.size(2)) \n","        ).view(bert_outputs.size(0), -1)      \n","        return self.fc(extracted_outputs)\n","\n","# Current model\n","class GAPModel(nn.Module):\n","    \"\"\"The main model.\"\"\"\n","    def __init__(self, bert_model: str, device: torch.device):\n","        super().__init__()\n","        self.device = device  # Setting GPU device\n","        if bert_model in (\"bert-base-uncased\", \"bert-base-cased\"):\n","            self.bert_hidden_size = 768\n","        elif bert_model in (\"bert-large-uncased\", \"bert-large-cased\"):\n","            self.bert_hidden_size = 1024\n","        else:\n","            raise ValueError(\"Unsupported BERT model.\")\n","        self.bert = BertModel.from_pretrained(bert_model).to(device)\n","        self.head = Head(self.bert_hidden_size).to(device)\n","    \n","    def forward(self, token_tensor, offsets):\n","        token_tensor = token_tensor.to(self.device)\n","        bert_outputs, _ =  self.bert(\n","            token_tensor, attention_mask=(token_tensor > 0).long(), \n","            token_type_ids=None, output_all_encoded_layers=False)\n","        head_outputs = self.head(bert_outputs, offsets.to(self.device))\n","        return head_outputs             "],"execution_count":156,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dN1qX6R0YNUy","executionInfo":{"status":"ok","timestamp":1623850305781,"user_tz":-180,"elapsed":247,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"21428285-5426-49f8-ccb5-30bbafca3524"},"source":["offsets = torch.tensor([[0,1,2],[1,2,3]])  # batch_size=2, len(A,B,P)= 3\n","print(offsets.shape)\n","offsets = offsets.unsqueeze(2)\n","print(offsets)\n","print(offsets.shape)"],"execution_count":157,"outputs":[{"output_type":"stream","text":["torch.Size([2, 3])\n","tensor([[[0],\n","         [1],\n","         [2]],\n","\n","        [[1],\n","         [2],\n","         [3]]])\n","torch.Size([2, 3, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZqmyLoEYPc3","executionInfo":{"status":"ok","timestamp":1623850306796,"user_tz":-180,"elapsed":3,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"7c679a03-f29d-461a-e0a3-6529109b1d24"},"source":["offsets=offsets.expand(-1,-1,5)   # bert_hidden_size=5\n","print(offsets)"],"execution_count":158,"outputs":[{"output_type":"stream","text":["tensor([[[0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1],\n","         [2, 2, 2, 2, 2]],\n","\n","        [[1, 1, 1, 1, 1],\n","         [2, 2, 2, 2, 2],\n","         [3, 3, 3, 3, 3]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KW4W0aQVYROH","executionInfo":{"status":"ok","timestamp":1623850307839,"user_tz":-180,"elapsed":3,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["bert_outputs = torch.tensor([[[ 1,  2,  3,  4,  5],\n","                  [ 6,  7,  8,  9, 10],\n","                  [11, 12, 13, 14, 15],\n","                  [16, 17, 18, 19, 20]],\n","                 [[21, 22, 23, 24, 25],\n","                  [26, 27, 28, 29, 30],\n","                  [31, 32, 33, 34, 35],\n","                  [36, 37, 38, 39, 40]]])"],"execution_count":159,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPLwDEMfYStt","executionInfo":{"status":"ok","timestamp":1623850308805,"user_tz":-180,"elapsed":9,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"2d489f33-6cc3-4c60-b113-b69803439029"},"source":["print(offsets.shape)\n","print(bert_outputs.shape)"],"execution_count":160,"outputs":[{"output_type":"stream","text":["torch.Size([2, 3, 5])\n","torch.Size([2, 4, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8QH4n4XYUef","executionInfo":{"status":"ok","timestamp":1623850309739,"user_tz":-180,"elapsed":3,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"265e477d-27dd-4c30-d052-1c0600276be0"},"source":["bert_outputs.gather(1,offsets)"],"execution_count":161,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 1,  2,  3,  4,  5],\n","         [ 6,  7,  8,  9, 10],\n","         [11, 12, 13, 14, 15]],\n","\n","        [[26, 27, 28, 29, 30],\n","         [31, 32, 33, 34, 35],\n","         [36, 37, 38, 39, 40]]])"]},"metadata":{"tags":[]},"execution_count":161}]},{"cell_type":"code","metadata":{"id":"Ke9ODhnhYWGR","executionInfo":{"status":"ok","timestamp":1623850310589,"user_tz":-180,"elapsed":3,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["def children(m):\n","    return m if isinstance(m, (list, tuple)) else list(m.children())\n","\n","def set_trainable_attr(m, b):\n","    m.trainable = b\n","    for p in m.parameters():\n","        p.requires_grad = b\n","\n","def apply_leaf(m, f):\n","    c = children(m)\n","    if isinstance(m, nn.Module):\n","        f(m)\n","    if len(c) > 0:\n","        for l in c:\n","            apply_leaf(l, f)\n","        \n","def set_trainable(l, b):\n","    apply_leaf(l, lambda m: set_trainable_attr(m, b))"],"execution_count":162,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzsmH4ebaQHk","executionInfo":{"status":"ok","timestamp":1623850312060,"user_tz":-180,"elapsed":238,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["class GAPBot(BaseBot):\n","    def __init__(self, model, train_loader, val_loader, optimizer, clip_grad=0,\n","        avg_window=100, log_dir=\"./cache/logs/\", log_level=logging.INFO,\n","        checkpoint_dir=\"./cache/model_cache/\", batch_idx=0, echo=False,\n","        device=\"cuda:0\", use_tensorboard=False):\n","        super().__init__(\n","            model, train_loader, val_loader, \n","            optimizer=optimizer, clip_grad=clip_grad,\n","            log_dir=log_dir, checkpoint_dir=checkpoint_dir, \n","            batch_idx=batch_idx, echo=echo,\n","            device=device, use_tensorboard=use_tensorboard\n","        )\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","        self.loss_format = \"%.6f\"\n","        \n","    def extract_prediction(self, tensor):\n","        return tensor\n","    \n","    # Logs\n","    def snapshot(self):\n","        loss = self.eval(self.val_loader)\n","        loss_str = self.loss_format % loss\n","        self.logger.info(\"Snapshot loss %s\", loss_str)\n","        self.logger.tb_scalars(\n","            \"losses\", {\"val\": loss},  self.step)\n","        target_path = (\n","            self.checkpoint_dir / \"best.pth\")        \n","        if not self.best_performers or (self.best_performers[0][0] > loss):\n","            torch.save(self.model.state_dict(), target_path)\n","            self.best_performers = [(loss, target_path, self.step)]\n","            self.logger.info(\"Saving checkpoint %s...\", target_path)\n","        else:\n","            new_loss_str = self.loss_format % self.best_performers[0][0]\n","            self.logger.info(\"This performance:%s is not as a good as our previously saved:%s\", loss_str,new_loss_str )\n","        assert Path(target_path).exists()\n","        return loss"],"execution_count":163,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqATX7RUYcb0","executionInfo":{"status":"ok","timestamp":1623850314205,"user_tz":-180,"elapsed":234,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["df_train = pd.read_csv(\"gap-test.tsv\", delimiter=\"\\t\")\n","df_val = pd.read_csv(\"gap-validation.tsv\", delimiter=\"\\t\")\n","df_test = pd.read_csv(\"../content/test_stage_2.tsv\", delimiter=\"\\t\")\n","sample_sub = pd.read_csv(\"../content/sample_submission_stage_2.csv\")\n","assert sample_sub.shape[0] == df_test.shape[0]"],"execution_count":164,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"ciz6037OYhPl","executionInfo":{"status":"ok","timestamp":1623850315332,"user_tz":-180,"elapsed":260,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"f44ac6ce-e1b3-481a-83bd-9444eb139e01"},"source":["print(len(df_train))\n","df_train.head()"],"execution_count":165,"outputs":[{"output_type":"stream","text":["2000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Text</th>\n","      <th>Pronoun</th>\n","      <th>Pronoun-offset</th>\n","      <th>A</th>\n","      <th>A-offset</th>\n","      <th>A-coref</th>\n","      <th>B</th>\n","      <th>B-offset</th>\n","      <th>B-coref</th>\n","      <th>URL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test-1</td>\n","      <td>Upon their acceptance into the Kontinental Hoc...</td>\n","      <td>His</td>\n","      <td>383</td>\n","      <td>Bob Suter</td>\n","      <td>352</td>\n","      <td>False</td>\n","      <td>Dehner</td>\n","      <td>366</td>\n","      <td>True</td>\n","      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test-2</td>\n","      <td>Between the years 1979-1981, River won four lo...</td>\n","      <td>him</td>\n","      <td>430</td>\n","      <td>Alonso</td>\n","      <td>353</td>\n","      <td>True</td>\n","      <td>Alfredo Di St*fano</td>\n","      <td>390</td>\n","      <td>False</td>\n","      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test-3</td>\n","      <td>Though his emigration from the country has aff...</td>\n","      <td>He</td>\n","      <td>312</td>\n","      <td>Ali Aladhadh</td>\n","      <td>256</td>\n","      <td>True</td>\n","      <td>Saddam</td>\n","      <td>295</td>\n","      <td>False</td>\n","      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test-4</td>\n","      <td>At the trial, Pisciotta said: ``Those who have...</td>\n","      <td>his</td>\n","      <td>526</td>\n","      <td>Alliata</td>\n","      <td>377</td>\n","      <td>False</td>\n","      <td>Pisciotta</td>\n","      <td>536</td>\n","      <td>True</td>\n","      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test-5</td>\n","      <td>It is about a pair of United States Navy shore...</td>\n","      <td>his</td>\n","      <td>406</td>\n","      <td>Eddie</td>\n","      <td>421</td>\n","      <td>True</td>\n","      <td>Rock Reilly</td>\n","      <td>559</td>\n","      <td>False</td>\n","      <td>http://en.wikipedia.org/wiki/Chasers</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       ID  ...                                             URL\n","0  test-1  ...      http://en.wikipedia.org/wiki/Jeremy_Dehner\n","1  test-2  ...    http://en.wikipedia.org/wiki/Norberto_Alonso\n","2  test-3  ...           http://en.wikipedia.org/wiki/Aladhadh\n","3  test-4  ...  http://en.wikipedia.org/wiki/Gaspare_Pisciotta\n","4  test-5  ...            http://en.wikipedia.org/wiki/Chasers\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":165}]},{"cell_type":"code","metadata":{"id":"F1BHRS7cY1Hv","executionInfo":{"status":"ok","timestamp":1623850316581,"user_tz":-180,"elapsed":319,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["BERT_MODEL = 'bert-large-uncased'\n","\n","tokenizer = BertTokenizer.from_pretrained(\n","    BERT_MODEL,\n","    do_lower_case=True,\n","    never_split = (\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\", \"[A]\", \"[B]\", \"[P]\")\n",")\n","# These tokens are not actually used, so we can assign arbitrary values.\n","tokenizer.vocab[\"[A]\"] = -1\n","tokenizer.vocab[\"[B]\"] = -1\n","tokenizer.vocab[\"[P]\"] = -1"],"execution_count":166,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PIdt2Vl1bsd","executionInfo":{"status":"ok","timestamp":1623850317749,"user_tz":-180,"elapsed":296,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"d732519f-e535-410f-a2a6-13909ab10658"},"source":["next(iter(test_loader))"],"execution_count":167,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[  101,  2005,  1996,  ...,     0,     0,     0],\n","         [  101,  2044,  2023,  ...,     0,     0,     0],\n","         [  101,  1999,  1996,  ...,     0,     0,     0],\n","         ...,\n","         [  101,  1999,  1996,  ...,     0,     0,     0],\n","         [  101,  1999, 15331,  ...,     0,     0,     0],\n","         [  101,  2044,  1996,  ...,     0,     0,     0]]),\n"," tensor([[ 18,  39,  69],\n","         [ 49,  65,  89],\n","         [ 48,  81,  72],\n","         [ 56,  75,  82],\n","         [ 55,  77,  81],\n","         [  6,  25,  32],\n","         [ 52,  54,  58],\n","         [ 70,  82,  85],\n","         [ 57,  76,  80],\n","         [ 55,  61,  68],\n","         [ 44,  63,  70],\n","         [ 51,  61,  67],\n","         [ 46,  52,  68],\n","         [ 41,  50,  54],\n","         [ 46,  54,  66],\n","         [ 19,  24,  33],\n","         [ 40,  47,  72],\n","         [ 43,  58,  64],\n","         [ 51,  57,  74],\n","         [ 42,  48,  54],\n","         [ 51,  62,  68],\n","         [ 44,  50,  57],\n","         [ 45,  47,  38],\n","         [ 36,  49,  63],\n","         [ 46,  51,  68],\n","         [ 61,  73,  83],\n","         [ 71,  85,  58],\n","         [ 37,  39,  43],\n","         [ 43,  46,  91],\n","         [ 49,  62,  82],\n","         [ 41,  57,  74],\n","         [ 45,  56,  67],\n","         [ 46,  59,  66],\n","         [ 78,  88,  96],\n","         [ 45,  67,  81],\n","         [ 48,  62,  78],\n","         [ 41,  48,  66],\n","         [  8,  19,  37],\n","         [ 59,  66,  70],\n","         [ 48,  54,  64],\n","         [ 40,  49,  57],\n","         [ 40,  48,  53],\n","         [ 51,  56,  40],\n","         [ 61,  69,  78],\n","         [ 41,  68,  75],\n","         [ 48,  53,  61],\n","         [ 59,  82,  80],\n","         [ 62,  69,  73],\n","         [ 42,  50,  53],\n","         [ 51,  63,  79],\n","         [ 16,  50,  65],\n","         [ 65,  82,  61],\n","         [ 72,  87,  95],\n","         [ 50,  55,  62],\n","         [ 61,  66,  74],\n","         [ 13,  22,  29],\n","         [  1,  10,  57],\n","         [ 42,  93,  65],\n","         [ 94, 102, 107],\n","         [ 53,  56,  61],\n","         [ 34,  43,  65],\n","         [ 69,  74,  77],\n","         [ 46,  71,  76],\n","         [ 42,  56,  75],\n","         [ 37,  48,  70],\n","         [ 40,  42,  45],\n","         [ 44,  47,  51],\n","         [ 56,  59,  51],\n","         [ 21,  25,  43],\n","         [ 62,  69,  78],\n","         [ 61,  73,  93],\n","         [ 16,  18,  38],\n","         [ 90, 100, 106],\n","         [ 40,  49,  54],\n","         [ 52,  60,  79],\n","         [ 47,  54,  57],\n","         [ 75,  85,  62],\n","         [ 67,  75,  63],\n","         [ 32,  43,  45],\n","         [ 28,  42,  45],\n","         [ 56,  63,  67],\n","         [ 61,  68,  76],\n","         [ 50,  57,  73],\n","         [  4,  12,  41],\n","         [ 40,  60,  34],\n","         [ 40,  52,  65],\n","         [ 53,  54,  56],\n","         [ 30,  54,  60],\n","         [ 51,  64,  69],\n","         [ 50,  55,  70],\n","         [ 45,  57,  66],\n","         [ 28,  45,  53],\n","         [ 37,  50,  82],\n","         [ 34,  38,  60],\n","         [ 59,  74,  78],\n","         [ 34,  40,  45],\n","         [ 24,  27,  34],\n","         [ 65,  74,  81],\n","         [ 53,  59,  64],\n","         [ 37,  46,  72],\n","         [ 80,  85,  72],\n","         [ 36,  43,  59],\n","         [  4,  43,  57],\n","         [ 35,  43,  55],\n","         [ 59,  75,  80],\n","         [ 81,  92,  95],\n","         [ 66,  82,  88],\n","         [ 56,  58,  64],\n","         [ 39,  63,  75],\n","         [ 53,  58,  65],\n","         [ 39,  51,  72],\n","         [ 54,  60,  65],\n","         [ 22,  43,  47],\n","         [ 47,  58,  66],\n","         [ 75,  79, 102],\n","         [ 49,  62,  65],\n","         [ 51,  68,  76],\n","         [ 77,  79,  70],\n","         [ 65,  70,  78],\n","         [ 68,  73,  91],\n","         [ 38,  57,  63],\n","         [ 25,  43,  60],\n","         [ 52,  62,  48],\n","         [ 44,  52,  57],\n","         [ 30,  34,  59],\n","         [ 45,  47,  75],\n","         [ 60,  73,  58],\n","         [ 53,  64,  67]]),\n"," None]"]},"metadata":{"tags":[]},"execution_count":167}]},{"cell_type":"markdown","metadata":{"id":"OWDkEPTikXPC"},"source":["## Making train,test and validation datasets"]},{"cell_type":"code","metadata":{"id":"jRxXxp6vY3O6","executionInfo":{"status":"ok","timestamp":1623853752557,"user_tz":-180,"elapsed":19812,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["train_ds = GAPDataset(df_train, tokenizer)\n","val_ds = GAPDataset(df_val, tokenizer)\n","val_ds2 = GAPDataset(df_val, tokenizer, labeled = False)\n","test_ds = GAPDataset(df_test, tokenizer, labeled=False)\n","# dataset convertation to dataloader\n","train_loader = DataLoader(\n","    train_ds,\n","    collate_fn = collate_examples,     #batch\n","    batch_size=20,\n","    num_workers=2,\n","    pin_memory=True,   # Using lock page memory，so that tensor transfer to cuda will be faster\n","    shuffle=True,\n","    drop_last=True     # Drop incomplete batch\n",")\n","val_loader = DataLoader(\n","    val_ds,\n","    collate_fn = collate_examples,\n","    batch_size=128,\n","    num_workers=2,\n","    pin_memory=True,\n","    shuffle=False\n",")\n","val_loader2 = DataLoader(\n","    val_ds2,\n","    collate_fn = collate_examples,\n","    batch_size=128,\n","    num_workers=2,\n","    pin_memory=True,\n","    shuffle=False\n",")\n","test_loader = DataLoader(\n","    test_ds,\n","    collate_fn = collate_examples,\n","    batch_size=128,\n","    num_workers=2,\n","    pin_memory=True,\n","    shuffle=False\n",")"],"execution_count":197,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGdpcNLeY5wG","executionInfo":{"status":"ok","timestamp":1623850353438,"user_tz":-180,"elapsed":232,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"5f5eb4b9-bd2b-49cf-96b8-cec4d712c7e0"},"source":["len(train_loader), len(test_loader), len(val_loader)"],"execution_count":172,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 97, 4)"]},"metadata":{"tags":[]},"execution_count":172}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOFgYbf8ZCfJ","executionInfo":{"status":"ok","timestamp":1623850403779,"user_tz":-180,"elapsed":49240,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"4b81c312-b086-46d0-bda2-75720b9ca407"},"source":["model = GAPModel(BERT_MODEL, device)\n","# You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n","set_trainable(model.bert, False)\n","set_trainable(model.head, True)"],"execution_count":174,"outputs":[{"output_type":"stream","text":["Initing batchnorm\n","Initing linear\n","Initing batchnorm\n","Initing linear\n","Initing batchnorm\n","Initing linear\n","Initing batchnorm\n","Initing linear\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WjVz72KPkkkJ"},"source":["## Adding hyperparametrs for optimization process"]},{"cell_type":"code","metadata":{"id":"eXc1An-uZIPX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623850405634,"user_tz":-180,"elapsed":242,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"72f353d6-4125-44af-d885-899f852ffe1c"},"source":["lr=1e-3\n","weight_decay=5e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","bot = GAPBot(\n","    model, train_loader, val_loader,\n","    optimizer=optimizer, echo=True,\n","    avg_window=25\n",")"],"execution_count":175,"outputs":[{"output_type":"stream","text":["[[06/16/2021 01:33:27 PM]] SEED: 420\n","[[06/16/2021 01:33:27 PM]] # of paramters: 340,403,203\n","[[06/16/2021 01:33:27 PM]] # of trainable paramters: 5,261,315\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"jMZyM5Efktfi"},"source":["# Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7NV50QyJePVa","executionInfo":{"status":"ok","timestamp":1623853003386,"user_tz":-180,"elapsed":2590480,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"c98f741d-6988-4096-da94-b484a38ca047"},"source":["steps_per_epoch = len(train_loader) \n","n_steps = steps_per_epoch * 27\n","bot.train(\n","    n_steps,\n","    log_interval=steps_per_epoch // 4,\n","    snapshot_interval=steps_per_epoch,\n","    scheduler=TriangularLR(\n","        optimizer, max_mul=20, ratio=2, steps_per_cycle=n_steps)\n",")   "],"execution_count":176,"outputs":[{"output_type":"stream","text":["[[06/16/2021 01:33:34 PM]] Optimizer Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    initial_lr: 0.001\n","    lr: 5e-05\n","    weight_decay: 0.005\n",")\n","[[06/16/2021 01:33:34 PM]] Batches per epoch: 100\n","[[06/16/2021 01:33:34 PM]] ====================Epoch 1====================\n","[[06/16/2021 01:33:53 PM]] Step 25: train 2.081881 lr: 7.533e-05\n","[[06/16/2021 01:34:10 PM]] Step 50: train 2.038459 lr: 1.017e-04\n","[[06/16/2021 01:34:27 PM]] Step 75: train 1.969777 lr: 1.281e-04\n","[[06/16/2021 01:34:47 PM]] Step 100: train 1.910000 lr: 1.545e-04\n","100%|██████████| 4/4 [00:18<00:00,  4.70s/it]\n","[[06/16/2021 01:35:05 PM]] Snapshot loss 0.937361\n","[[06/16/2021 01:35:10 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/16/2021 01:35:10 PM]] New low\n","\n","[[06/16/2021 01:35:11 PM]] ====================Epoch 2====================\n","[[06/16/2021 01:35:29 PM]] Step 125: train 1.858720 lr: 1.809e-04\n","[[06/16/2021 01:35:47 PM]] Step 150: train 1.796178 lr: 2.073e-04\n","[[06/16/2021 01:36:04 PM]] Step 175: train 1.759216 lr: 2.337e-04\n","[[06/16/2021 01:36:23 PM]] Step 200: train 1.709331 lr: 2.601e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 01:36:42 PM]] Snapshot loss 0.859828\n","[[06/16/2021 01:36:47 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/16/2021 01:36:47 PM]] New low\n","\n","[[06/16/2021 01:36:47 PM]] ====================Epoch 3====================\n","[[06/16/2021 01:37:06 PM]] Step 225: train 1.679212 lr: 2.864e-04\n","[[06/16/2021 01:37:25 PM]] Step 250: train 1.644120 lr: 3.128e-04\n","[[06/16/2021 01:37:43 PM]] Step 275: train 1.609474 lr: 3.392e-04\n","[[06/16/2021 01:38:03 PM]] Step 300: train 1.570296 lr: 3.656e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 01:38:22 PM]] Snapshot loss 0.812460\n","[[06/16/2021 01:38:27 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/16/2021 01:38:27 PM]] New low\n","\n","[[06/16/2021 01:38:28 PM]] ====================Epoch 4====================\n","[[06/16/2021 01:38:47 PM]] Step 325: train 1.501655 lr: 3.920e-04\n","[[06/16/2021 01:39:05 PM]] Step 350: train 1.445005 lr: 4.184e-04\n","[[06/16/2021 01:39:23 PM]] Step 375: train 1.386066 lr: 4.448e-04\n","[[06/16/2021 01:39:44 PM]] Step 400: train 1.333338 lr: 4.712e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.77s/it]\n","[[06/16/2021 01:40:03 PM]] Snapshot loss 0.772478\n","[[06/16/2021 01:40:10 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/16/2021 01:40:10 PM]] New low\n","\n","[[06/16/2021 01:40:10 PM]] ====================Epoch 5====================\n","[[06/16/2021 01:40:30 PM]] Step 425: train 1.285339 lr: 4.976e-04\n","[[06/16/2021 01:40:49 PM]] Step 450: train 1.238236 lr: 5.239e-04\n","[[06/16/2021 01:41:06 PM]] Step 475: train 1.194173 lr: 5.503e-04\n","[[06/16/2021 01:41:26 PM]] Step 500: train 1.176512 lr: 5.767e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.77s/it]\n","[[06/16/2021 01:41:45 PM]] Snapshot loss 0.722838\n","[[06/16/2021 01:41:50 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/16/2021 01:41:50 PM]] New low\n","\n","[[06/16/2021 01:41:50 PM]] ====================Epoch 6====================\n","[[06/16/2021 01:42:08 PM]] Step 525: train 1.130258 lr: 6.031e-04\n","[[06/16/2021 01:42:28 PM]] Step 550: train 1.098597 lr: 6.295e-04\n","[[06/16/2021 01:42:46 PM]] Step 575: train 1.068330 lr: 6.559e-04\n","[[06/16/2021 01:43:06 PM]] Step 600: train 1.050834 lr: 6.823e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.78s/it]\n","[[06/16/2021 01:43:25 PM]] Snapshot loss 0.736336\n","[[06/16/2021 01:43:25 PM]] This performance:0.736336 is not as a good as our previously saved:0.722838\n","[[06/16/2021 01:43:25 PM]] ====================Epoch 7====================\n","[[06/16/2021 01:43:42 PM]] Step 625: train 1.018515 lr: 7.087e-04\n","[[06/16/2021 01:43:59 PM]] Step 650: train 0.985981 lr: 7.351e-04\n","[[06/16/2021 01:44:18 PM]] Step 675: train 0.964110 lr: 7.614e-04\n","[[06/16/2021 01:44:39 PM]] Step 700: train 0.938532 lr: 7.878e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 01:44:58 PM]] Snapshot loss 0.665610\n","[[06/16/2021 01:45:04 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/16/2021 01:45:05 PM]] New low\n","\n","[[06/16/2021 01:45:05 PM]] ====================Epoch 8====================\n","[[06/16/2021 01:45:24 PM]] Step 725: train 0.904138 lr: 8.142e-04\n","[[06/16/2021 01:45:43 PM]] Step 750: train 0.894125 lr: 8.406e-04\n","[[06/16/2021 01:46:02 PM]] Step 775: train 0.873085 lr: 8.670e-04\n","[[06/16/2021 01:46:20 PM]] Step 800: train 0.833559 lr: 8.934e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.78s/it]\n","[[06/16/2021 01:46:40 PM]] Snapshot loss 0.622676\n","[[06/16/2021 01:46:46 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/16/2021 01:46:46 PM]] New low\n","\n","[[06/16/2021 01:46:46 PM]] ====================Epoch 9====================\n","[[06/16/2021 01:47:05 PM]] Step 825: train 0.815233 lr: 9.198e-04\n","[[06/16/2021 01:47:24 PM]] Step 850: train 0.786574 lr: 9.462e-04\n","[[06/16/2021 01:47:43 PM]] Step 875: train 0.773727 lr: 9.726e-04\n","[[06/16/2021 01:48:02 PM]] Step 900: train 0.756479 lr: 9.989e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.77s/it]\n","[[06/16/2021 01:48:21 PM]] Snapshot loss 0.666508\n","[[06/16/2021 01:48:21 PM]] This performance:0.666508 is not as a good as our previously saved:0.622676\n","[[06/16/2021 01:48:21 PM]] ====================Epoch 10====================\n","[[06/16/2021 01:48:40 PM]] Step 925: train 0.732569 lr: 9.873e-04\n","[[06/16/2021 01:48:58 PM]] Step 950: train 0.706361 lr: 9.741e-04\n","[[06/16/2021 01:49:17 PM]] Step 975: train 0.686564 lr: 9.609e-04\n","[[06/16/2021 01:49:36 PM]] Step 1000: train 0.676227 lr: 9.478e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.78s/it]\n","[[06/16/2021 01:49:55 PM]] Snapshot loss 0.643531\n","[[06/16/2021 01:49:55 PM]] This performance:0.643531 is not as a good as our previously saved:0.622676\n","[[06/16/2021 01:49:55 PM]] ====================Epoch 11====================\n","[[06/16/2021 01:50:13 PM]] Step 1025: train 0.659918 lr: 9.346e-04\n","[[06/16/2021 01:50:31 PM]] Step 1050: train 0.641554 lr: 9.214e-04\n","[[06/16/2021 01:50:51 PM]] Step 1075: train 0.625581 lr: 9.082e-04\n","[[06/16/2021 01:51:10 PM]] Step 1100: train 0.617321 lr: 8.950e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.78s/it]\n","[[06/16/2021 01:51:30 PM]] Snapshot loss 0.667273\n","[[06/16/2021 01:51:30 PM]] This performance:0.667273 is not as a good as our previously saved:0.622676\n","[[06/16/2021 01:51:30 PM]] ====================Epoch 12====================\n","[[06/16/2021 01:51:50 PM]] Step 1125: train 0.595617 lr: 8.818e-04\n","[[06/16/2021 01:52:08 PM]] Step 1150: train 0.584380 lr: 8.686e-04\n","[[06/16/2021 01:52:26 PM]] Step 1175: train 0.564491 lr: 8.554e-04\n","[[06/16/2021 01:52:43 PM]] Step 1200: train 0.546352 lr: 8.422e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 01:53:02 PM]] Snapshot loss 0.630016\n","[[06/16/2021 01:53:02 PM]] This performance:0.630016 is not as a good as our previously saved:0.622676\n","[[06/16/2021 01:53:03 PM]] ====================Epoch 13====================\n","[[06/16/2021 01:53:23 PM]] Step 1225: train 0.527976 lr: 8.290e-04\n","[[06/16/2021 01:53:41 PM]] Step 1250: train 0.514664 lr: 8.158e-04\n","[[06/16/2021 01:53:59 PM]] Step 1275: train 0.499298 lr: 8.026e-04\n","[[06/16/2021 01:54:18 PM]] Step 1300: train 0.489704 lr: 7.894e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.80s/it]\n","[[06/16/2021 01:54:37 PM]] Snapshot loss 0.643471\n","[[06/16/2021 01:54:37 PM]] This performance:0.643471 is not as a good as our previously saved:0.622676\n","[[06/16/2021 01:54:37 PM]] ====================Epoch 14====================\n","[[06/16/2021 01:54:55 PM]] Step 1325: train 0.493354 lr: 7.762e-04\n","[[06/16/2021 01:55:14 PM]] Step 1350: train 0.475274 lr: 7.630e-04\n","[[06/16/2021 01:55:33 PM]] Step 1375: train 0.467096 lr: 7.498e-04\n","[[06/16/2021 01:55:52 PM]] Step 1400: train 0.462588 lr: 7.366e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 01:56:11 PM]] Snapshot loss 0.609070\n","[[06/16/2021 01:56:17 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/16/2021 01:56:17 PM]] New low\n","\n","[[06/16/2021 01:56:17 PM]] ====================Epoch 15====================\n","[[06/16/2021 01:56:37 PM]] Step 1425: train 0.462214 lr: 7.234e-04\n","[[06/16/2021 01:56:56 PM]] Step 1450: train 0.456414 lr: 7.102e-04\n","[[06/16/2021 01:57:14 PM]] Step 1475: train 0.444821 lr: 6.971e-04\n","[[06/16/2021 01:57:33 PM]] Step 1500: train 0.440016 lr: 6.839e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.76s/it]\n","[[06/16/2021 01:57:52 PM]] Snapshot loss 0.618377\n","[[06/16/2021 01:57:52 PM]] This performance:0.618377 is not as a good as our previously saved:0.609070\n","[[06/16/2021 01:57:52 PM]] ====================Epoch 16====================\n","[[06/16/2021 01:58:11 PM]] Step 1525: train 0.439304 lr: 6.707e-04\n","[[06/16/2021 01:58:31 PM]] Step 1550: train 0.438633 lr: 6.575e-04\n","[[06/16/2021 01:58:51 PM]] Step 1575: train 0.430797 lr: 6.443e-04\n","[[06/16/2021 01:59:08 PM]] Step 1600: train 0.417948 lr: 6.311e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 01:59:27 PM]] Snapshot loss 0.618472\n","[[06/16/2021 01:59:27 PM]] This performance:0.618472 is not as a good as our previously saved:0.609070\n","[[06/16/2021 01:59:27 PM]] ====================Epoch 17====================\n","[[06/16/2021 01:59:45 PM]] Step 1625: train 0.409173 lr: 6.179e-04\n","[[06/16/2021 02:00:03 PM]] Step 1650: train 0.412100 lr: 6.047e-04\n","[[06/16/2021 02:00:22 PM]] Step 1675: train 0.405820 lr: 5.915e-04\n","[[06/16/2021 02:00:42 PM]] Step 1700: train 0.395028 lr: 5.783e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.81s/it]\n","[[06/16/2021 02:01:01 PM]] Snapshot loss 0.613548\n","[[06/16/2021 02:01:01 PM]] This performance:0.613548 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:01:01 PM]] ====================Epoch 18====================\n","[[06/16/2021 02:01:19 PM]] Step 1725: train 0.392356 lr: 5.651e-04\n","[[06/16/2021 02:01:36 PM]] Step 1750: train 0.390961 lr: 5.519e-04\n","[[06/16/2021 02:01:56 PM]] Step 1775: train 0.394169 lr: 5.387e-04\n","[[06/16/2021 02:02:16 PM]] Step 1800: train 0.385288 lr: 5.255e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.80s/it]\n","[[06/16/2021 02:02:35 PM]] Snapshot loss 0.615226\n","[[06/16/2021 02:02:35 PM]] This performance:0.615226 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:02:36 PM]] ====================Epoch 19====================\n","[[06/16/2021 02:02:55 PM]] Step 1825: train 0.384334 lr: 5.123e-04\n","[[06/16/2021 02:03:12 PM]] Step 1850: train 0.376588 lr: 4.991e-04\n","[[06/16/2021 02:03:31 PM]] Step 1875: train 0.378905 lr: 4.859e-04\n","[[06/16/2021 02:03:50 PM]] Step 1900: train 0.376142 lr: 4.727e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.78s/it]\n","[[06/16/2021 02:04:09 PM]] Snapshot loss 0.658949\n","[[06/16/2021 02:04:09 PM]] This performance:0.658949 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:04:09 PM]] ====================Epoch 20====================\n","[[06/16/2021 02:04:28 PM]] Step 1925: train 0.367362 lr: 4.596e-04\n","[[06/16/2021 02:04:45 PM]] Step 1950: train 0.361616 lr: 4.464e-04\n","[[06/16/2021 02:05:04 PM]] Step 1975: train 0.353681 lr: 4.332e-04\n","[[06/16/2021 02:05:23 PM]] Step 2000: train 0.347834 lr: 4.200e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 02:05:42 PM]] Snapshot loss 0.660855\n","[[06/16/2021 02:05:42 PM]] This performance:0.660855 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:05:42 PM]] ====================Epoch 21====================\n","[[06/16/2021 02:06:01 PM]] Step 2025: train 0.341315 lr: 4.068e-04\n","[[06/16/2021 02:06:19 PM]] Step 2050: train 0.333193 lr: 3.936e-04\n","[[06/16/2021 02:06:40 PM]] Step 2075: train 0.326836 lr: 3.804e-04\n","[[06/16/2021 02:06:58 PM]] Step 2100: train 0.327105 lr: 3.672e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.80s/it]\n","[[06/16/2021 02:07:17 PM]] Snapshot loss 0.627331\n","[[06/16/2021 02:07:17 PM]] This performance:0.627331 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:07:17 PM]] ====================Epoch 22====================\n","[[06/16/2021 02:07:36 PM]] Step 2125: train 0.322278 lr: 3.540e-04\n","[[06/16/2021 02:07:54 PM]] Step 2150: train 0.321004 lr: 3.408e-04\n","[[06/16/2021 02:08:13 PM]] Step 2175: train 0.311992 lr: 3.276e-04\n","[[06/16/2021 02:08:33 PM]] Step 2200: train 0.306840 lr: 3.144e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.78s/it]\n","[[06/16/2021 02:08:52 PM]] Snapshot loss 0.621453\n","[[06/16/2021 02:08:52 PM]] This performance:0.621453 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:08:52 PM]] ====================Epoch 23====================\n","[[06/16/2021 02:09:10 PM]] Step 2225: train 0.306266 lr: 3.012e-04\n","[[06/16/2021 02:09:28 PM]] Step 2250: train 0.302564 lr: 2.880e-04\n","[[06/16/2021 02:09:46 PM]] Step 2275: train 0.300231 lr: 2.748e-04\n","[[06/16/2021 02:10:06 PM]] Step 2300: train 0.297836 lr: 2.616e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 02:10:25 PM]] Snapshot loss 0.616350\n","[[06/16/2021 02:10:25 PM]] This performance:0.616350 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:10:25 PM]] ====================Epoch 24====================\n","[[06/16/2021 02:10:43 PM]] Step 2325: train 0.296076 lr: 2.484e-04\n","[[06/16/2021 02:11:01 PM]] Step 2350: train 0.294721 lr: 2.352e-04\n","[[06/16/2021 02:11:22 PM]] Step 2375: train 0.288783 lr: 2.221e-04\n","[[06/16/2021 02:11:41 PM]] Step 2400: train 0.283126 lr: 2.089e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.77s/it]\n","[[06/16/2021 02:12:00 PM]] Snapshot loss 0.633524\n","[[06/16/2021 02:12:00 PM]] This performance:0.633524 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:12:00 PM]] ====================Epoch 25====================\n","[[06/16/2021 02:12:19 PM]] Step 2425: train 0.282791 lr: 1.957e-04\n","[[06/16/2021 02:12:39 PM]] Step 2450: train 0.279830 lr: 1.825e-04\n","[[06/16/2021 02:12:56 PM]] Step 2475: train 0.282221 lr: 1.693e-04\n","[[06/16/2021 02:13:16 PM]] Step 2500: train 0.277197 lr: 1.561e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 02:13:35 PM]] Snapshot loss 0.645574\n","[[06/16/2021 02:13:35 PM]] This performance:0.645574 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:13:35 PM]] ====================Epoch 26====================\n","[[06/16/2021 02:13:53 PM]] Step 2525: train 0.274682 lr: 1.429e-04\n","[[06/16/2021 02:14:14 PM]] Step 2550: train 0.276239 lr: 1.297e-04\n","[[06/16/2021 02:14:33 PM]] Step 2575: train 0.271888 lr: 1.165e-04\n","[[06/16/2021 02:14:50 PM]] Step 2600: train 0.271116 lr: 1.033e-04\n","100%|██████████| 4/4 [00:19<00:00,  4.77s/it]\n","[[06/16/2021 02:15:10 PM]] Snapshot loss 0.650389\n","[[06/16/2021 02:15:10 PM]] This performance:0.650389 is not as a good as our previously saved:0.609070\n","[[06/16/2021 02:15:10 PM]] ====================Epoch 27====================\n","[[06/16/2021 02:15:27 PM]] Step 2625: train 0.269681 lr: 9.011e-05\n","[[06/16/2021 02:15:46 PM]] Step 2650: train 0.267513 lr: 7.692e-05\n","[[06/16/2021 02:16:07 PM]] Step 2675: train 0.264365 lr: 6.372e-05\n","[[06/16/2021 02:16:25 PM]] Step 2700: train 0.259623 lr: 5.053e-05\n","100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n","[[06/16/2021 02:16:44 PM]] Snapshot loss 0.656686\n","[[06/16/2021 02:16:44 PM]] This performance:0.656686 is not as a good as our previously saved:0.609070\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9mbyxIdXfYy5","executionInfo":{"status":"ok","timestamp":1623853068038,"user_tz":-180,"elapsed":5296,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["torch.save(model.state_dict(), './model.pth')"],"execution_count":177,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ndmPlUHfa2O","executionInfo":{"status":"ok","timestamp":1623853777326,"user_tz":-180,"elapsed":4,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["# Predict function\n","def predict(loader, *, return_y=False):\n","    model.eval()\n","    outputs, y_global = [], []\n","    with torch.set_grad_enabled(False):\n","        for input_tensors in loader:\n","            input_tensors = [x.to(model.device) for x in input_tensors if x is not None]\n","            outputs.append(bot.predict_batch(input_tensors).cpu())\n","        outputs = torch.cat(outputs, dim=0)\n","    return outputs"],"execution_count":201,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kAe1W6U_kzPl"},"source":["# Predict"]},{"cell_type":"code","metadata":{"id":"ORIble07fbR4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623853796879,"user_tz":-180,"elapsed":18415,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"5b232a37-9ea0-45ca-9e8d-d7bbb77bba34"},"source":["preds = predict(val_loader2)\n","len(preds)"],"execution_count":202,"outputs":[{"output_type":"execute_result","data":{"text/plain":["454"]},"metadata":{"tags":[]},"execution_count":202}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZEuJKLEa35D","executionInfo":{"status":"ok","timestamp":1623853807960,"user_tz":-180,"elapsed":298,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"abd3c6a8-6b78-4d75-cad3-3f00452df675"},"source":["preds"],"execution_count":203,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.6400,  0.7500, -1.9589],\n","        [-2.5454,  2.0033, -0.5670],\n","        [ 0.9716,  1.0074, -1.5044],\n","        ...,\n","        [-0.0057,  2.9075, -2.7485],\n","        [-0.0288,  3.3687, -3.1830],\n","        [ 1.7442,  0.8780, -2.0920]])"]},"metadata":{"tags":[]},"execution_count":203}]},{"cell_type":"code","metadata":{"id":"4_yLk1L0ff5b","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1623853830001,"user_tz":-180,"elapsed":255,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"8dae10a9-2a45-472f-cd93-640dfb3fc482"},"source":["df_sub = pd.DataFrame(torch.softmax(preds, -1).cpu().numpy().clip(1e-3, 1-1e-3), columns=[\"A\", \"B\", \"NEITHER\"])\n","df_sub[\"ID\"] = df_test.ID\n","df_sub.head()"],"execution_count":205,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>NEITHER</th>\n","      <th>ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.695402</td>\n","      <td>0.285576</td>\n","      <td>0.019022</td>\n","      <td>000075809a8e6b062f5fb3c191a8ed52</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.009732</td>\n","      <td>0.919890</td>\n","      <td>0.070377</td>\n","      <td>0005d0f3b0a6c9ffbd31a48453029911</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.471579</td>\n","      <td>0.488770</td>\n","      <td>0.039651</td>\n","      <td>0007775c40bedd4147a0573d66dc28f8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.878121</td>\n","      <td>0.050952</td>\n","      <td>0.070927</td>\n","      <td>001194e3fe1234d00198ef6bba4cc588</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.917470</td>\n","      <td>0.063986</td>\n","      <td>0.018545</td>\n","      <td>0014bb7085278ef3f9b74f14771caca9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          A         B   NEITHER                                ID\n","0  0.695402  0.285576  0.019022  000075809a8e6b062f5fb3c191a8ed52\n","1  0.009732  0.919890  0.070377  0005d0f3b0a6c9ffbd31a48453029911\n","2  0.471579  0.488770  0.039651  0007775c40bedd4147a0573d66dc28f8\n","3  0.878121  0.050952  0.070927  001194e3fe1234d00198ef6bba4cc588\n","4  0.917470  0.063986  0.018545  0014bb7085278ef3f9b74f14771caca9"]},"metadata":{"tags":[]},"execution_count":205}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"1b1GLA1eCDa2","executionInfo":{"status":"ok","timestamp":1623854114820,"user_tz":-180,"elapsed":250,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"ee8017ff-60e5-445d-d756-354705b23037"},"source":["df_val_results = pd.DataFrame(columns=[\"A\", \"B\", \"NEITHER\"])\n","df_val_results['A'] = df_val['A-coref'] > df_val['B-coref']\n","df_val_results['B'] = df_val['B-coref'] > df_val['A-coref']\n","df_val_results['NEITHER'] = ~(df_val_results['A'] | df_val_results['B'])\n","df_val_results"],"execution_count":207,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>NEITHER</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>449</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>450</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>451</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>452</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>453</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>454 rows × 3 columns</p>\n","</div>"],"text/plain":["         A      B  NEITHER\n","0    False  False     True\n","1    False   True    False\n","2    False   True    False\n","3     True  False    False\n","4    False   True    False\n","..     ...    ...      ...\n","449  False  False     True\n","450  False  False     True\n","451  False   True    False\n","452  False   True    False\n","453   True  False    False\n","\n","[454 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":207}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"jfx0VM_tNJSh","executionInfo":{"status":"ok","timestamp":1623854183082,"user_tz":-180,"elapsed":242,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"003ef83f-6dcb-4086-d869-06bfc076f333"},"source":["df_val_results = pd.DataFrame(columns=[\"A\", \"B\", \"NEITHER\"])\n","df_val_results['A'] = df_val['A-coref'] > df_val['B-coref']\n","df_val_results['B'] = df_val['B-coref'] > df_val['A-coref']\n","df_val_results['NEITHER'] = ~(df_val_results['A'] | df_val_results['B'])\n","df_val_results"],"execution_count":212,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>NEITHER</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>449</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>450</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>451</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>452</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>453</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>454 rows × 3 columns</p>\n","</div>"],"text/plain":["         A      B  NEITHER\n","0    False  False     True\n","1    False   True    False\n","2    False   True    False\n","3     True  False    False\n","4    False   True    False\n","..     ...    ...      ...\n","449  False  False     True\n","450  False  False     True\n","451  False   True    False\n","452  False   True    False\n","453   True  False    False\n","\n","[454 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":212}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"ITBwJZZWQf4X","executionInfo":{"status":"ok","timestamp":1623854383356,"user_tz":-180,"elapsed":253,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"462057b0-4988-40f4-dc7a-3673f40f1572"},"source":["df_preds = pd.DataFrame(preds.cpu().numpy(),columns = ['A','B','NEITHER'])\n","df_preds"],"execution_count":220,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>NEITHER</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.640018</td>\n","      <td>0.750037</td>\n","      <td>-1.958881</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-2.545449</td>\n","      <td>2.003340</td>\n","      <td>-0.567045</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.971577</td>\n","      <td>1.007383</td>\n","      <td>-1.504389</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.127079</td>\n","      <td>-0.719820</td>\n","      <td>-0.389059</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.568884</td>\n","      <td>-0.094078</td>\n","      <td>-1.332553</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>449</th>\n","      <td>0.080464</td>\n","      <td>0.402899</td>\n","      <td>-0.124440</td>\n","    </tr>\n","    <tr>\n","      <th>450</th>\n","      <td>0.837947</td>\n","      <td>0.998932</td>\n","      <td>-1.460450</td>\n","    </tr>\n","    <tr>\n","      <th>451</th>\n","      <td>-0.005680</td>\n","      <td>2.907465</td>\n","      <td>-2.748477</td>\n","    </tr>\n","    <tr>\n","      <th>452</th>\n","      <td>-0.028786</td>\n","      <td>3.368730</td>\n","      <td>-3.182956</td>\n","    </tr>\n","    <tr>\n","      <th>453</th>\n","      <td>1.744164</td>\n","      <td>0.878026</td>\n","      <td>-2.092018</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>454 rows × 3 columns</p>\n","</div>"],"text/plain":["            A         B   NEITHER\n","0    1.640018  0.750037 -1.958881\n","1   -2.545449  2.003340 -0.567045\n","2    0.971577  1.007383 -1.504389\n","3    2.127079 -0.719820 -0.389059\n","4    2.568884 -0.094078 -1.332553\n","..        ...       ...       ...\n","449  0.080464  0.402899 -0.124440\n","450  0.837947  0.998932 -1.460450\n","451 -0.005680  2.907465 -2.748477\n","452 -0.028786  3.368730 -3.182956\n","453  1.744164  0.878026 -2.092018\n","\n","[454 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":220}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"dO_Kmt0bQ6Ir","executionInfo":{"status":"ok","timestamp":1623854435291,"user_tz":-180,"elapsed":241,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"9977bd4f-2d0a-4723-f4c6-3875fbc0de1a"},"source":["df_preds_results = pd.DataFrame(columns=[\"A\", \"B\", \"NEITHER\"])\n","df_preds_results['A'] = df_preds['A'] > df_preds['B']\n","df_preds_results['B'] = df_preds['B'] > df_preds['A']\n","df_preds_results['NEITHER'] = ~(df_preds_results['A'] | df_preds_results['B'])\n","df_preds_results"],"execution_count":221,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>NEITHER</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>449</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>450</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>451</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>452</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>453</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>454 rows × 3 columns</p>\n","</div>"],"text/plain":["         A      B  NEITHER\n","0     True  False    False\n","1    False   True    False\n","2    False   True    False\n","3     True  False    False\n","4     True  False    False\n","..     ...    ...      ...\n","449  False   True    False\n","450  False   True    False\n","451  False   True    False\n","452  False   True    False\n","453   True  False    False\n","\n","[454 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":221}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSR_If3Ph9CX","executionInfo":{"status":"ok","timestamp":1623854451600,"user_tz":-180,"elapsed":253,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"b7529de2-7be3-4ebe-c04c-2f4a4ee3dc2f"},"source":["print(classification_report(df_val_results, df_preds_results))"],"execution_count":222,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.73      0.89      0.80       187\n","           1       0.77      0.84      0.80       205\n","           2       0.00      0.00      0.00        62\n","\n","   micro avg       0.75      0.75      0.75       454\n","   macro avg       0.50      0.58      0.53       454\n","weighted avg       0.65      0.75      0.69       454\n"," samples avg       0.75      0.75      0.75       454\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]}]}