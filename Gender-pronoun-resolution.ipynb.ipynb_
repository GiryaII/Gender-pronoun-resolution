{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Копия блокнота \"ML project.ipynb\"","provenance":[{"file_id":"1F5JaUSKJ_IXzVobx4LjEGYrhPI6A-I6Y","timestamp":1623695024148},{"file_id":"1c4_O25_p46FV_5dU9Zy29iEutA223Sqe","timestamp":1621590195173}],"authorship_tag":"ABX9TyME4mxfoVqwTp0PijUDGxx4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"e2jyYuFBj9CR"},"source":["# Import and loading data\n"]},{"cell_type":"code","metadata":{"id":"c0HEZybdxK7u","executionInfo":{"status":"ok","timestamp":1623681245228,"user_tz":-180,"elapsed":329,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["import numpy as np \n","import pandas as pd \n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjmiT6a4xO9u","executionInfo":{"status":"ok","timestamp":1623681288490,"user_tz":-180,"elapsed":1788,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-development.tsv -q\n","!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-test.tsv -q\n","!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-validation.tsv -q"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tXOPMAbMd_Pr","executionInfo":{"status":"ok","timestamp":1623681284687,"user_tz":-180,"elapsed":322,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"6430c6ba-42d1-4f83-aa82-dd442bad297b"},"source":["device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","device = torch.device(device)\n","print(device)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiAyumvNxRYc","executionInfo":{"status":"ok","timestamp":1623681306689,"user_tz":-180,"elapsed":14065,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"8bec6343-e741-4a34-e4f0-10e29d7ceac1"},"source":["!pip install pytorch-pretrained-bert\n","!pip install https://github.com/ceshine/pytorch_helper_bot/archive/0.0.4.zip"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 12.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.1+cu101)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/94/4774265ce7a53c38f93e062e8b5ffea3f0ec1efde9e8d91d81e2d6ccd7e8/boto3-1.17.93-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 23.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting s3transfer<0.5.0,>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.6MB/s \n","\u001b[?25hCollecting botocore<1.21.0,>=1.20.93\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/fe/0348a318ee4f9f0240bad0171c5384d68c30de4d6b1e9a40464c59ed927d/botocore-1.20.93-py2.py3-none-any.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 20.2MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.93->boto3->pytorch-pretrained-bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.93->boto3->pytorch-pretrained-bert) (1.15.0)\n","\u001b[31mERROR: botocore 1.20.93 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","Successfully installed boto3-1.17.93 botocore-1.20.93 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2\n","Collecting https://github.com/ceshine/pytorch_helper_bot/archive/0.0.4.zip\n","\u001b[?25l  Downloading https://github.com/ceshine/pytorch_helper_bot/archive/0.0.4.zip\n","\u001b[K     | 30kB 38.1MB/s\n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from PyTorchHelperBot==0.0.4) (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->PyTorchHelperBot==0.0.4) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->PyTorchHelperBot==0.0.4) (1.19.5)\n","Building wheels for collected packages: PyTorchHelperBot\n","  Building wheel for PyTorchHelperBot (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyTorchHelperBot: filename=PyTorchHelperBot-0.0.4-cp37-none-any.whl size=7180 sha256=fda5e5da4365fe9f50d2e4222f4eb17888a007e6666f94728a5ff7749212c5b3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8vfvsvh6/wheels/1f/01/01/da39a14e8e30666f3eec7106664e59059789c330a11b5fa357\n","Successfully built PyTorchHelperBot\n","Installing collected packages: PyTorchHelperBot\n","Successfully installed PyTorchHelperBot-0.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wVp-a4gWxUdJ","executionInfo":{"status":"ok","timestamp":1623681323540,"user_tz":-180,"elapsed":512,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["import os\n","\n","# This variable is used by helperbot to make the training deterministic\n","os.environ[\"SEED\"] = \"420\"\n","\n","import logging\n","from pathlib import Path\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from pytorch_pretrained_bert import BertTokenizer\n","from pytorch_pretrained_bert.modeling import BertModel\n","\n","from helperbot import BaseBot, TriangularLR, WeightDecayOptimizerWrapper"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k9yfU4qYkIPe"},"source":["# Preparation functions"]},{"cell_type":"code","metadata":{"id":"0njedZqOxest","executionInfo":{"status":"ok","timestamp":1623681326676,"user_tz":-180,"elapsed":461,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["def insert_tag(row):\n","    \"\"\"Insert custom tags to help us find the position of A, B, and the pronoun after tokenization.\"\"\"\n","    to_be_inserted = sorted([\n","        (row[\"A-offset\"], \" [A] \"),\n","        (row[\"B-offset\"], \" [B] \"),\n","        (row[\"Pronoun-offset\"], \" [P] \")\n","    ], key=lambda x: x[0], reverse=True)\n","    text = row[\"Text\"]\n","    for offset, tag in to_be_inserted:\n","        text = text[:offset] + tag + text[offset:]\n","    return text\n","\n","def tokenize(text, tokenizer):\n","    \"\"\"Returns a list of tokens and the positions of A, B, and the pronoun.\"\"\"\n","    entries = {}\n","    final_tokens = []\n","    for token in tokenizer.tokenize(text):\n","        if token in (\"[A]\", \"[B]\", \"[P]\"):\n","            entries[token] = len(final_tokens)\n","            continue\n","        final_tokens.append(token)\n","    return final_tokens, (entries[\"[A]\"], entries[\"[B]\"], entries[\"[P]\"])\n","\n","class GAPDataset(Dataset):\n","    \"\"\"Custom GAP Dataset class\"\"\"\n","    def __init__(self, df, tokenizer, labeled=True):\n","        self.labeled = labeled\n","        if labeled:\n","            tmp = df[[\"A-coref\", \"B-coref\"]].copy()\n","            tmp[\"Neither\"] = ~(df[\"A-coref\"] | df[\"B-coref\"])\n","            self.y = tmp.values.astype(\"bool\")\n","\n","        # Extracts the tokens and offsets(positions of A, B, and P)\n","        self.offsets, self.tokens = [], []\n","        for _, row in df.iterrows():\n","            text = insert_tag(row)\n","            tokens, offsets = tokenize(text, tokenizer)\n","            self.offsets.append(offsets)\n","            self.tokens.append(tokenizer.convert_tokens_to_ids(\n","                [\"[CLS]\"] + tokens + [\"[SEP]\"]))\n","        \n","    def __len__(self):\n","        return len(self.tokens)\n","\n","    def __getitem__(self, idx):\n","        if self.labeled:\n","            return self.tokens[idx], self.offsets[idx], self.y[idx]\n","        return self.tokens[idx], self.offsets[idx]\n","    \n","def collate_examples(batch, truncate_len=500):\n","    \"\"\"Batch preparation.\n","    \n","    1. Pad the sequences\n","    2. Transform the target.\n","    \"\"\"\n","    transposed = list(zip(*batch))\n","    max_len = min(\n","        max((len(x) for x in transposed[0])),\n","        truncate_len\n","    )\n","    tokens = np.zeros((len(batch), max_len), dtype=np.int64)\n","    for i, row in enumerate(transposed[0]):\n","        row = np.array(row[:truncate_len])\n","        tokens[i, :len(row)] = row\n","    token_tensor = torch.from_numpy(tokens)\n","    # Offsets\n","    offsets = torch.stack([\n","        torch.LongTensor(x) for x in transposed[1]\n","    ], dim=0) + 1 # Account for the [CLS] token\n","    # Labels\n","    if len(transposed) == 2:\n","        return token_tensor, offsets, None\n","    one_hot_labels = torch.stack([\n","        torch.from_numpy(x.astype(\"uint8\")) for x in transposed[2]\n","    ], dim=0)\n","    _, labels = one_hot_labels.max(dim=1)\n","    return token_tensor, offsets, labels\n","\n","def collate_examples_no_labels(batch, truncate_len=500):\n","    \"\"\"Batch preparation.\n","    \n","    1. Pad the sequences\n","    2. Transform the target.\n","    \"\"\"\n","    transposed = list(zip(*batch))\n","    print(\"transposed size is\", transposed.size())\n","    max_len = min(\n","        max((len(x) for x in transposed[0])),\n","        truncate_len\n","    )\n","    tokens = np.zeros((len(batch), max_len), dtype=np.int64)\n","    for i, row in enumerate(transposed[0]):\n","        row = np.array(row[:truncate_len])\n","        tokens[i, :len(row)] = row\n","    token_tensor = torch.from_numpy(tokens)\n","    # Offsets\n","    offsets = torch.stack([\n","        torch.LongTensor(x) for x in transposed[1]\n","    ], dim=0) + 1 # Account for the [CLS] token\n","    # Labels\n","    if len(transposed) == 2:\n","        return token_tensor, offsets, None\n","    one_hot_labels = torch.stack([\n","        torch.from_numpy(x.astype(\"uint8\")) for x in transposed[2]\n","    ], dim=0)\n","    _, labels = one_hot_labels.max(dim=1)\n","    return token_tensor, offsets, labels\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bETMoEtSkN3H"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"zSyhR-vCYLnq","executionInfo":{"status":"ok","timestamp":1623681329721,"user_tz":-180,"elapsed":5,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["# Classical MLP model\n","class Head(nn.Module):\n","    \"\"\"The MLP submodule\"\"\"\n","    def __init__(self, bert_hidden_size: int):\n","        super().__init__()\n","        self.head_hidden_size = 1024  # MLP hidden size\n","        self.bert_hidden_size = bert_hidden_size   # Bert hidden size\n","        self.fc = nn.Sequential(\n","            nn.BatchNorm1d(bert_hidden_size * 3),  # Batch Normalization * 3 is because the bert_output of A,B is expanded into 1 dimension\n","            nn.Dropout(0.5),                       # Random deactivation\n","            nn.Linear(bert_hidden_size * 3, self.head_hidden_size), # Linear layer\n","            nn.ReLU(),                                              # Activation function\n","            nn.BatchNorm1d(self.head_hidden_size),\n","            nn.Dropout(0.5),\n","            nn.Linear(self.head_hidden_size, self.head_hidden_size),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(self.head_hidden_size),\n","            nn.Dropout(0.5),\n","            nn.Linear(self.head_hidden_size, self.head_hidden_size),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(self.head_hidden_size),\n","            nn.Dropout(0.5),\n","            nn.Linear(self.head_hidden_size, 3)\n","        )\n","        \n","        # Parametrs inialization\n","        for i, module in enumerate(self.fc):\n","            if isinstance(module, (nn.BatchNorm1d, nn.BatchNorm2d)):\n","                nn.init.constant_(module.weight, 1)\n","                nn.init.constant_(module.bias, 0)\n","                print(\"Initing batchnorm\")\n","            elif isinstance(module, nn.Linear):\n","                if getattr(module, \"weight_v\", None) is not None:\n","                    nn.init.uniform_(module.weight_g, 0, 1)\n","                    nn.init.kaiming_normal_(module.weight_v)\n","                    print(\"Initing linear with weight normalization\")\n","                    assert model[i].weight_g is not None\n","                else:\n","                    nn.init.kaiming_normal_(module.weight)\n","                    print(\"Initing linear\")\n","                nn.init.constant_(module.bias, 0)\n","    \n","    # Forward propagation\n","    def forward(self, bert_outputs, offsets):\n","        # bert_outputs:[batch_size, seq_length, hidden_szie]\n","        assert bert_outputs.size(2) == self.bert_hidden_size   \n","        \n","        # Taking out the embeddings at the offsets of A and B\n","        # unsqueeze(2):Expand 2-dimensional offsets to 3-dimensional\n","        # Extend a dimension of size 1. Such as (2,2,1) expands to (2,2,3)\n","        # input.gather(dim,index), index the specified dimension。For example, for a 4*3 tensor,indexing dim=1,then the value of index is 0~2.\n","        extracted_outputs = bert_outputs.gather(\n","            1, offsets.unsqueeze(2).expand(-1, -1, bert_outputs.size(2)) \n","        ).view(bert_outputs.size(0), -1)      \n","        return self.fc(extracted_outputs)\n","\n","# Current model\n","class GAPModel(nn.Module):\n","    \"\"\"The main model.\"\"\"\n","    def __init__(self, bert_model: str, device: torch.device):\n","        super().__init__()\n","        self.device = device  # Setting GPU device\n","        if bert_model in (\"bert-base-uncased\", \"bert-base-cased\"):\n","            self.bert_hidden_size = 768\n","        elif bert_model in (\"bert-large-uncased\", \"bert-large-cased\"):\n","            self.bert_hidden_size = 1024\n","        else:\n","            raise ValueError(\"Unsupported BERT model.\")\n","        self.bert = BertModel.from_pretrained(bert_model).to(device)\n","        self.head = Head(self.bert_hidden_size).to(device)\n","    \n","    def forward(self, token_tensor, offsets):\n","        token_tensor = token_tensor.to(self.device)\n","        bert_outputs, _ =  self.bert(\n","            token_tensor, attention_mask=(token_tensor > 0).long(), \n","            token_type_ids=None, output_all_encoded_layers=False)\n","        head_outputs = self.head(bert_outputs, offsets.to(self.device))\n","        return head_outputs             "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dN1qX6R0YNUy","executionInfo":{"status":"ok","timestamp":1623681339345,"user_tz":-180,"elapsed":303,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"a02f1198-8300-437d-d75c-1537b526e800"},"source":["offsets = torch.tensor([[0,1,2],[1,2,3]])  # batch_size=2, len(A,B,P)= 3\n","print(offsets.shape)\n","offsets = offsets.unsqueeze(2)\n","print(offsets)\n","print(offsets.shape)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["torch.Size([2, 3])\n","tensor([[[0],\n","         [1],\n","         [2]],\n","\n","        [[1],\n","         [2],\n","         [3]]])\n","torch.Size([2, 3, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZqmyLoEYPc3","executionInfo":{"status":"ok","timestamp":1623681340986,"user_tz":-180,"elapsed":6,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"c282fba3-6c5f-49d2-9136-3418465dbfab"},"source":["offsets=offsets.expand(-1,-1,5)   # 假设bert_hidden_size=5\n","print(offsets)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor([[[0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1],\n","         [2, 2, 2, 2, 2]],\n","\n","        [[1, 1, 1, 1, 1],\n","         [2, 2, 2, 2, 2],\n","         [3, 3, 3, 3, 3]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KW4W0aQVYROH","executionInfo":{"status":"ok","timestamp":1623681342437,"user_tz":-180,"elapsed":2,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["bert_outputs = torch.tensor([[[ 1,  2,  3,  4,  5],\n","                  [ 6,  7,  8,  9, 10],\n","                  [11, 12, 13, 14, 15],\n","                  [16, 17, 18, 19, 20]],\n","                 [[21, 22, 23, 24, 25],\n","                  [26, 27, 28, 29, 30],\n","                  [31, 32, 33, 34, 35],\n","                  [36, 37, 38, 39, 40]]])"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPLwDEMfYStt","executionInfo":{"status":"ok","timestamp":1623681345117,"user_tz":-180,"elapsed":503,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"3036ce97-6202-4f36-8841-23f235da04c3"},"source":["print(offsets.shape)\n","print(bert_outputs.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["torch.Size([2, 3, 5])\n","torch.Size([2, 4, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8QH4n4XYUef","executionInfo":{"status":"ok","timestamp":1623681347120,"user_tz":-180,"elapsed":8,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"f37f1755-2d44-4255-e5a1-45f13a998fe0"},"source":["bert_outputs.gather(1,offsets)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 1,  2,  3,  4,  5],\n","         [ 6,  7,  8,  9, 10],\n","         [11, 12, 13, 14, 15]],\n","\n","        [[26, 27, 28, 29, 30],\n","         [31, 32, 33, 34, 35],\n","         [36, 37, 38, 39, 40]]])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"Ke9ODhnhYWGR","executionInfo":{"status":"ok","timestamp":1623681348936,"user_tz":-180,"elapsed":3,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["def children(m):\n","    return m if isinstance(m, (list, tuple)) else list(m.children())\n","\n","def set_trainable_attr(m, b):\n","    m.trainable = b\n","    for p in m.parameters():\n","        p.requires_grad = b\n","\n","def apply_leaf(m, f):\n","    c = children(m)\n","    if isinstance(m, nn.Module):\n","        f(m)\n","    if len(c) > 0:\n","        for l in c:\n","            apply_leaf(l, f)\n","        \n","def set_trainable(l, b):\n","    apply_leaf(l, lambda m: set_trainable_attr(m, b))"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzsmH4ebaQHk","executionInfo":{"status":"ok","timestamp":1623681350887,"user_tz":-180,"elapsed":307,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["class GAPBot(BaseBot):\n","    def __init__(self, model, train_loader, val_loader, optimizer, clip_grad=0,\n","        avg_window=100, log_dir=\"./cache/logs/\", log_level=logging.INFO,\n","        checkpoint_dir=\"./cache/model_cache/\", batch_idx=0, echo=False,\n","        device=\"cuda:0\", use_tensorboard=False):\n","        super().__init__(\n","            model, train_loader, val_loader, \n","            optimizer=optimizer, clip_grad=clip_grad,\n","            log_dir=log_dir, checkpoint_dir=checkpoint_dir, \n","            batch_idx=batch_idx, echo=echo,\n","            device=device, use_tensorboard=use_tensorboard\n","        )\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","        self.loss_format = \"%.6f\"\n","        \n","    def extract_prediction(self, tensor):\n","        return tensor\n","    \n","    # Logs\n","    def snapshot(self):\n","        loss = self.eval(self.val_loader)\n","        loss_str = self.loss_format % loss\n","        self.logger.info(\"Snapshot loss %s\", loss_str)\n","        self.logger.tb_scalars(\n","            \"losses\", {\"val\": loss},  self.step)\n","        target_path = (\n","            self.checkpoint_dir / \"best.pth\")        \n","        if not self.best_performers or (self.best_performers[0][0] > loss):\n","            torch.save(self.model.state_dict(), target_path)\n","            self.best_performers = [(loss, target_path, self.step)]\n","            self.logger.info(\"Saving checkpoint %s...\", target_path)\n","        else:\n","            new_loss_str = self.loss_format % self.best_performers[0][0]\n","            self.logger.info(\"This performance:%s is not as a good as our previously saved:%s\", loss_str,new_loss_str )\n","        assert Path(target_path).exists()\n","        return loss"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqATX7RUYcb0","executionInfo":{"status":"ok","timestamp":1623681409681,"user_tz":-180,"elapsed":305,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["df_train = pd.read_csv(\"gap-test.tsv\", delimiter=\"\\t\")\n","df_val = pd.read_csv(\"gap-validation.tsv\", delimiter=\"\\t\")\n","df_test = pd.read_csv(\"../content/test_stage_2.tsv\", delimiter=\"\\t\")\n","sample_sub = pd.read_csv(\"../content/sample_submission_stage_2.csv\")\n","assert sample_sub.shape[0] == df_test.shape[0]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"ciz6037OYhPl","executionInfo":{"status":"ok","timestamp":1623681412371,"user_tz":-180,"elapsed":318,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"cdd6f4d3-dca4-4e91-adfd-edc1f1503f2c"},"source":["print(len(df_train))\n","df_train.head()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["2000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Text</th>\n","      <th>Pronoun</th>\n","      <th>Pronoun-offset</th>\n","      <th>A</th>\n","      <th>A-offset</th>\n","      <th>A-coref</th>\n","      <th>B</th>\n","      <th>B-offset</th>\n","      <th>B-coref</th>\n","      <th>URL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test-1</td>\n","      <td>Upon their acceptance into the Kontinental Hoc...</td>\n","      <td>His</td>\n","      <td>383</td>\n","      <td>Bob Suter</td>\n","      <td>352</td>\n","      <td>False</td>\n","      <td>Dehner</td>\n","      <td>366</td>\n","      <td>True</td>\n","      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test-2</td>\n","      <td>Between the years 1979-1981, River won four lo...</td>\n","      <td>him</td>\n","      <td>430</td>\n","      <td>Alonso</td>\n","      <td>353</td>\n","      <td>True</td>\n","      <td>Alfredo Di St*fano</td>\n","      <td>390</td>\n","      <td>False</td>\n","      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test-3</td>\n","      <td>Though his emigration from the country has aff...</td>\n","      <td>He</td>\n","      <td>312</td>\n","      <td>Ali Aladhadh</td>\n","      <td>256</td>\n","      <td>True</td>\n","      <td>Saddam</td>\n","      <td>295</td>\n","      <td>False</td>\n","      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test-4</td>\n","      <td>At the trial, Pisciotta said: ``Those who have...</td>\n","      <td>his</td>\n","      <td>526</td>\n","      <td>Alliata</td>\n","      <td>377</td>\n","      <td>False</td>\n","      <td>Pisciotta</td>\n","      <td>536</td>\n","      <td>True</td>\n","      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test-5</td>\n","      <td>It is about a pair of United States Navy shore...</td>\n","      <td>his</td>\n","      <td>406</td>\n","      <td>Eddie</td>\n","      <td>421</td>\n","      <td>True</td>\n","      <td>Rock Reilly</td>\n","      <td>559</td>\n","      <td>False</td>\n","      <td>http://en.wikipedia.org/wiki/Chasers</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       ID  ...                                             URL\n","0  test-1  ...      http://en.wikipedia.org/wiki/Jeremy_Dehner\n","1  test-2  ...    http://en.wikipedia.org/wiki/Norberto_Alonso\n","2  test-3  ...           http://en.wikipedia.org/wiki/Aladhadh\n","3  test-4  ...  http://en.wikipedia.org/wiki/Gaspare_Pisciotta\n","4  test-5  ...            http://en.wikipedia.org/wiki/Chasers\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"F1BHRS7cY1Hv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623681415620,"user_tz":-180,"elapsed":1567,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"893b9985-8e4e-4601-bcb3-51a3b0703dbf"},"source":["BERT_MODEL = 'bert-large-uncased'\n","\n","tokenizer = BertTokenizer.from_pretrained(\n","    BERT_MODEL,\n","    do_lower_case=True,\n","    never_split = (\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\", \"[A]\", \"[B]\", \"[P]\")\n",")\n","# These tokens are not actually used, so we can assign arbitrary values.\n","tokenizer.vocab[\"[A]\"] = -1\n","tokenizer.vocab[\"[B]\"] = -1\n","tokenizer.vocab[\"[P]\"] = -1"],"execution_count":22,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 701213.30B/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OWDkEPTikXPC"},"source":["## Making train,test and validation datasets"]},{"cell_type":"code","metadata":{"id":"jRxXxp6vY3O6","executionInfo":{"status":"ok","timestamp":1623681444723,"user_tz":-180,"elapsed":25161,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["train_ds = GAPDataset(df_train, tokenizer)\n","val_ds = GAPDataset(df_val, tokenizer)\n","test_ds = GAPDataset(df_test, tokenizer, labeled=False)\n","# dataset convertation to dataloader\n","train_loader = DataLoader(\n","    train_ds,\n","    collate_fn = collate_examples,     #batch\n","    batch_size=20,\n","    num_workers=2,\n","    pin_memory=True,   # Using lock page memory，so that tensor transfer to cuda will be faster\n","    shuffle=True,\n","    drop_last=True     # Drop incomplete batch\n",")\n","val_loader = DataLoader(\n","    val_ds,\n","    collate_fn = collate_examples,\n","    batch_size=128,\n","    num_workers=2,\n","    pin_memory=True,\n","    shuffle=False\n",")\n","test_loader = DataLoader(\n","    test_ds,\n","    collate_fn = collate_examples,\n","    batch_size=128,\n","    num_workers=2,\n","    pin_memory=True,\n","    shuffle=False\n",")"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGdpcNLeY5wG","executionInfo":{"status":"ok","timestamp":1623681462556,"user_tz":-180,"elapsed":394,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"150d5e01-e9ce-4f62-b5fd-06b8d9e9e2ba"},"source":["len(train_loader), len(test_loader), len(val_loader)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 97, 4)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0pCCLV2ZADN","executionInfo":{"status":"ok","timestamp":1623681472728,"user_tz":-180,"elapsed":9029,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"66fea355-dd3e-4816-8696-9b4f4ea40c9a"},"source":["next(iter(test_loader))"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[  101,  2005,  1996,  ...,     0,     0,     0],\n","         [  101,  2044,  2023,  ...,     0,     0,     0],\n","         [  101,  1999,  1996,  ...,     0,     0,     0],\n","         ...,\n","         [  101,  1999,  1996,  ...,     0,     0,     0],\n","         [  101,  1999, 15331,  ...,     0,     0,     0],\n","         [  101,  2044,  1996,  ...,     0,     0,     0]]),\n"," tensor([[ 18,  39,  69],\n","         [ 49,  65,  89],\n","         [ 48,  81,  72],\n","         [ 56,  75,  82],\n","         [ 55,  77,  81],\n","         [  6,  25,  32],\n","         [ 52,  54,  58],\n","         [ 70,  82,  85],\n","         [ 57,  76,  80],\n","         [ 55,  61,  68],\n","         [ 44,  63,  70],\n","         [ 51,  61,  67],\n","         [ 46,  52,  68],\n","         [ 41,  50,  54],\n","         [ 46,  54,  66],\n","         [ 19,  24,  33],\n","         [ 40,  47,  72],\n","         [ 43,  58,  64],\n","         [ 51,  57,  74],\n","         [ 42,  48,  54],\n","         [ 51,  62,  68],\n","         [ 44,  50,  57],\n","         [ 45,  47,  38],\n","         [ 36,  49,  63],\n","         [ 46,  51,  68],\n","         [ 61,  73,  83],\n","         [ 71,  85,  58],\n","         [ 37,  39,  43],\n","         [ 43,  46,  91],\n","         [ 49,  62,  82],\n","         [ 41,  57,  74],\n","         [ 45,  56,  67],\n","         [ 46,  59,  66],\n","         [ 78,  88,  96],\n","         [ 45,  67,  81],\n","         [ 48,  62,  78],\n","         [ 41,  48,  66],\n","         [  8,  19,  37],\n","         [ 59,  66,  70],\n","         [ 48,  54,  64],\n","         [ 40,  49,  57],\n","         [ 40,  48,  53],\n","         [ 51,  56,  40],\n","         [ 61,  69,  78],\n","         [ 41,  68,  75],\n","         [ 48,  53,  61],\n","         [ 59,  82,  80],\n","         [ 62,  69,  73],\n","         [ 42,  50,  53],\n","         [ 51,  63,  79],\n","         [ 16,  50,  65],\n","         [ 65,  82,  61],\n","         [ 72,  87,  95],\n","         [ 50,  55,  62],\n","         [ 61,  66,  74],\n","         [ 13,  22,  29],\n","         [  1,  10,  57],\n","         [ 42,  93,  65],\n","         [ 94, 102, 107],\n","         [ 53,  56,  61],\n","         [ 34,  43,  65],\n","         [ 69,  74,  77],\n","         [ 46,  71,  76],\n","         [ 42,  56,  75],\n","         [ 37,  48,  70],\n","         [ 40,  42,  45],\n","         [ 44,  47,  51],\n","         [ 56,  59,  51],\n","         [ 21,  25,  43],\n","         [ 62,  69,  78],\n","         [ 61,  73,  93],\n","         [ 16,  18,  38],\n","         [ 90, 100, 106],\n","         [ 40,  49,  54],\n","         [ 52,  60,  79],\n","         [ 47,  54,  57],\n","         [ 75,  85,  62],\n","         [ 67,  75,  63],\n","         [ 32,  43,  45],\n","         [ 28,  42,  45],\n","         [ 56,  63,  67],\n","         [ 61,  68,  76],\n","         [ 50,  57,  73],\n","         [  4,  12,  41],\n","         [ 40,  60,  34],\n","         [ 40,  52,  65],\n","         [ 53,  54,  56],\n","         [ 30,  54,  60],\n","         [ 51,  64,  69],\n","         [ 50,  55,  70],\n","         [ 45,  57,  66],\n","         [ 28,  45,  53],\n","         [ 37,  50,  82],\n","         [ 34,  38,  60],\n","         [ 59,  74,  78],\n","         [ 34,  40,  45],\n","         [ 24,  27,  34],\n","         [ 65,  74,  81],\n","         [ 53,  59,  64],\n","         [ 37,  46,  72],\n","         [ 80,  85,  72],\n","         [ 36,  43,  59],\n","         [  4,  43,  57],\n","         [ 35,  43,  55],\n","         [ 59,  75,  80],\n","         [ 81,  92,  95],\n","         [ 66,  82,  88],\n","         [ 56,  58,  64],\n","         [ 39,  63,  75],\n","         [ 53,  58,  65],\n","         [ 39,  51,  72],\n","         [ 54,  60,  65],\n","         [ 22,  43,  47],\n","         [ 47,  58,  66],\n","         [ 75,  79, 102],\n","         [ 49,  62,  65],\n","         [ 51,  68,  76],\n","         [ 77,  79,  70],\n","         [ 65,  70,  78],\n","         [ 68,  73,  91],\n","         [ 38,  57,  63],\n","         [ 25,  43,  60],\n","         [ 52,  62,  48],\n","         [ 44,  52,  57],\n","         [ 30,  34,  59],\n","         [ 45,  47,  75],\n","         [ 60,  73,  58],\n","         [ 53,  64,  67]]),\n"," None]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOFgYbf8ZCfJ","executionInfo":{"status":"ok","timestamp":1623681563726,"user_tz":-180,"elapsed":88067,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"0e38eb48-5496-4409-b497-1e879ce47b0a"},"source":["model = GAPModel(BERT_MODEL, device)\n","# You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n","set_trainable(model.bert, False)\n","set_trainable(model.head, True)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["100%|██████████| 1248501532/1248501532 [00:39<00:00, 31532978.93B/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Initing batchnorm\n","Initing linear\n","Initing batchnorm\n","Initing linear\n","Initing batchnorm\n","Initing linear\n","Initing batchnorm\n","Initing linear\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WjVz72KPkkkJ"},"source":["## Adding hyperparametrs for optimization process"]},{"cell_type":"code","metadata":{"id":"eXc1An-uZIPX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623681570043,"user_tz":-180,"elapsed":362,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"740e56a3-ced3-4ed9-d2c4-7fc9e08f2e6c"},"source":["lr=1e-3\n","weight_decay=5e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","bot = GAPBot(\n","    model, train_loader, val_loader,\n","    optimizer=optimizer, echo=True,\n","    avg_window=25\n",")"],"execution_count":27,"outputs":[{"output_type":"stream","text":["[[06/14/2021 02:39:29 PM]] SEED: 420\n","[[06/14/2021 02:39:29 PM]] # of paramters: 340,403,203\n","[[06/14/2021 02:39:29 PM]] # of trainable paramters: 5,261,315\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"jMZyM5Efktfi"},"source":["# Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7NV50QyJePVa","executionInfo":{"status":"ok","timestamp":1623688519342,"user_tz":-180,"elapsed":6937621,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"03fb43d6-1272-403e-be8f-edf73aa6ae3f"},"source":["steps_per_epoch = len(train_loader) \n","n_steps = steps_per_epoch * 27\n","bot.train(\n","    n_steps,\n","    log_interval=steps_per_epoch // 4,\n","    snapshot_interval=steps_per_epoch,\n","    scheduler=TriangularLR(\n","        optimizer, max_mul=20, ratio=2, steps_per_cycle=n_steps)\n",")   "],"execution_count":28,"outputs":[{"output_type":"stream","text":["[[06/14/2021 02:39:41 PM]] Optimizer Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    initial_lr: 0.001\n","    lr: 5e-05\n","    weight_decay: 0.005\n",")\n","[[06/14/2021 02:39:41 PM]] Batches per epoch: 100\n","[[06/14/2021 02:39:41 PM]] ====================Epoch 1====================\n","[[06/14/2021 02:40:34 PM]] Step 25: train 2.052181 lr: 7.533e-05\n","[[06/14/2021 02:41:28 PM]] Step 50: train 1.928328 lr: 1.017e-04\n","[[06/14/2021 02:42:21 PM]] Step 75: train 1.922204 lr: 1.281e-04\n","[[06/14/2021 02:43:13 PM]] Step 100: train 1.870402 lr: 1.545e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.42s/it]\n","[[06/14/2021 02:43:59 PM]] Snapshot loss 0.921929\n","[[06/14/2021 02:44:04 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/14/2021 02:44:04 PM]] New low\n","\n","[[06/14/2021 02:44:04 PM]] ====================Epoch 2====================\n","[[06/14/2021 02:44:58 PM]] Step 125: train 1.822521 lr: 1.809e-04\n","[[06/14/2021 02:45:51 PM]] Step 150: train 1.786613 lr: 2.073e-04\n","[[06/14/2021 02:46:45 PM]] Step 175: train 1.755970 lr: 2.337e-04\n","[[06/14/2021 02:47:36 PM]] Step 200: train 1.717566 lr: 2.601e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.41s/it]\n","[[06/14/2021 02:48:21 PM]] Snapshot loss 0.806288\n","[[06/14/2021 02:48:28 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/14/2021 02:48:28 PM]] New low\n","\n","[[06/14/2021 02:48:28 PM]] ====================Epoch 3====================\n","[[06/14/2021 02:49:20 PM]] Step 225: train 1.668027 lr: 2.864e-04\n","[[06/14/2021 02:50:16 PM]] Step 250: train 1.637150 lr: 3.128e-04\n","[[06/14/2021 02:51:05 PM]] Step 275: train 1.611126 lr: 3.392e-04\n","[[06/14/2021 02:51:58 PM]] Step 300: train 1.600544 lr: 3.656e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.40s/it]\n","[[06/14/2021 02:52:44 PM]] Snapshot loss 0.767995\n","[[06/14/2021 02:52:49 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/14/2021 02:52:49 PM]] New low\n","\n","[[06/14/2021 02:52:49 PM]] ====================Epoch 4====================\n","[[06/14/2021 02:53:40 PM]] Step 325: train 1.523573 lr: 3.920e-04\n","[[06/14/2021 02:54:33 PM]] Step 350: train 1.459838 lr: 4.184e-04\n","[[06/14/2021 02:55:24 PM]] Step 375: train 1.392257 lr: 4.448e-04\n","[[06/14/2021 02:56:19 PM]] Step 400: train 1.357488 lr: 4.712e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.38s/it]\n","[[06/14/2021 02:57:04 PM]] Snapshot loss 0.755788\n","[[06/14/2021 02:57:10 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/14/2021 02:57:10 PM]] New low\n","\n","[[06/14/2021 02:57:10 PM]] ====================Epoch 5====================\n","[[06/14/2021 02:58:02 PM]] Step 425: train 1.306947 lr: 4.976e-04\n","[[06/14/2021 02:58:56 PM]] Step 450: train 1.256380 lr: 5.239e-04\n","[[06/14/2021 02:59:45 PM]] Step 475: train 1.212275 lr: 5.503e-04\n","[[06/14/2021 03:00:40 PM]] Step 500: train 1.179966 lr: 5.767e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.37s/it]\n","[[06/14/2021 03:01:25 PM]] Snapshot loss 0.753900\n","[[06/14/2021 03:01:31 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/14/2021 03:01:31 PM]] New low\n","\n","[[06/14/2021 03:01:31 PM]] ====================Epoch 6====================\n","[[06/14/2021 03:02:23 PM]] Step 525: train 1.156727 lr: 6.031e-04\n","[[06/14/2021 03:03:15 PM]] Step 550: train 1.128992 lr: 6.295e-04\n","[[06/14/2021 03:04:08 PM]] Step 575: train 1.100589 lr: 6.559e-04\n","[[06/14/2021 03:05:00 PM]] Step 600: train 1.042466 lr: 6.823e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 03:05:46 PM]] Snapshot loss 0.803086\n","[[06/14/2021 03:05:46 PM]] This performance:0.803086 is not as a good as our previously saved:0.753900\n","[[06/14/2021 03:05:46 PM]] ====================Epoch 7====================\n","[[06/14/2021 03:06:37 PM]] Step 625: train 1.018657 lr: 7.087e-04\n","[[06/14/2021 03:07:31 PM]] Step 650: train 1.002547 lr: 7.351e-04\n","[[06/14/2021 03:08:24 PM]] Step 675: train 0.979918 lr: 7.614e-04\n","[[06/14/2021 03:09:16 PM]] Step 700: train 0.945574 lr: 7.878e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.37s/it]\n","[[06/14/2021 03:10:01 PM]] Snapshot loss 0.670752\n","[[06/14/2021 03:10:07 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/14/2021 03:10:07 PM]] New low\n","\n","[[06/14/2021 03:10:07 PM]] ====================Epoch 8====================\n","[[06/14/2021 03:10:58 PM]] Step 725: train 0.915857 lr: 8.142e-04\n","[[06/14/2021 03:11:49 PM]] Step 750: train 0.895099 lr: 8.406e-04\n","[[06/14/2021 03:12:41 PM]] Step 775: train 0.878697 lr: 8.670e-04\n","[[06/14/2021 03:13:38 PM]] Step 800: train 0.855259 lr: 8.934e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 03:14:23 PM]] Snapshot loss 0.710134\n","[[06/14/2021 03:14:23 PM]] This performance:0.710134 is not as a good as our previously saved:0.670752\n","[[06/14/2021 03:14:24 PM]] ====================Epoch 9====================\n","[[06/14/2021 03:15:18 PM]] Step 825: train 0.824625 lr: 9.198e-04\n","[[06/14/2021 03:16:08 PM]] Step 850: train 0.791886 lr: 9.462e-04\n","[[06/14/2021 03:17:02 PM]] Step 875: train 0.762338 lr: 9.726e-04\n","[[06/14/2021 03:17:53 PM]] Step 900: train 0.754722 lr: 9.989e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.38s/it]\n","[[06/14/2021 03:18:39 PM]] Snapshot loss 0.742649\n","[[06/14/2021 03:18:39 PM]] This performance:0.742649 is not as a good as our previously saved:0.670752\n","[[06/14/2021 03:18:39 PM]] ====================Epoch 10====================\n","[[06/14/2021 03:19:28 PM]] Step 925: train 0.739664 lr: 9.873e-04\n","[[06/14/2021 03:20:20 PM]] Step 950: train 0.723210 lr: 9.741e-04\n","[[06/14/2021 03:21:10 PM]] Step 975: train 0.701087 lr: 9.609e-04\n","[[06/14/2021 03:22:08 PM]] Step 1000: train 0.677428 lr: 9.478e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 03:22:54 PM]] Snapshot loss 0.722456\n","[[06/14/2021 03:22:54 PM]] This performance:0.722456 is not as a good as our previously saved:0.670752\n","[[06/14/2021 03:22:54 PM]] ====================Epoch 11====================\n","[[06/14/2021 03:23:46 PM]] Step 1025: train 0.672366 lr: 9.346e-04\n","[[06/14/2021 03:24:37 PM]] Step 1050: train 0.655211 lr: 9.214e-04\n","[[06/14/2021 03:25:30 PM]] Step 1075: train 0.634771 lr: 9.082e-04\n","[[06/14/2021 03:26:24 PM]] Step 1100: train 0.617221 lr: 8.950e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.37s/it]\n","[[06/14/2021 03:27:10 PM]] Snapshot loss 0.638736\n","[[06/14/2021 03:27:15 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/14/2021 03:27:15 PM]] New low\n","\n","[[06/14/2021 03:27:15 PM]] ====================Epoch 12====================\n","[[06/14/2021 03:28:11 PM]] Step 1125: train 0.603819 lr: 8.818e-04\n","[[06/14/2021 03:29:03 PM]] Step 1150: train 0.592447 lr: 8.686e-04\n","[[06/14/2021 03:29:55 PM]] Step 1175: train 0.576673 lr: 8.554e-04\n","[[06/14/2021 03:30:44 PM]] Step 1200: train 0.565359 lr: 8.422e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.37s/it]\n","[[06/14/2021 03:31:29 PM]] Snapshot loss 0.588879\n","[[06/14/2021 03:31:35 PM]] Saving checkpoint cache/model_cache/best.pth...\n","[[06/14/2021 03:31:35 PM]] New low\n","\n","[[06/14/2021 03:31:35 PM]] ====================Epoch 13====================\n","[[06/14/2021 03:32:27 PM]] Step 1225: train 0.547604 lr: 8.290e-04\n","[[06/14/2021 03:33:18 PM]] Step 1250: train 0.531955 lr: 8.158e-04\n","[[06/14/2021 03:34:11 PM]] Step 1275: train 0.526300 lr: 8.026e-04\n","[[06/14/2021 03:35:04 PM]] Step 1300: train 0.515805 lr: 7.894e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 03:35:50 PM]] Snapshot loss 0.647933\n","[[06/14/2021 03:35:50 PM]] This performance:0.647933 is not as a good as our previously saved:0.588879\n","[[06/14/2021 03:35:50 PM]] ====================Epoch 14====================\n","[[06/14/2021 03:36:36 PM]] Step 1325: train 0.503881 lr: 7.762e-04\n","[[06/14/2021 03:37:30 PM]] Step 1350: train 0.495792 lr: 7.630e-04\n","[[06/14/2021 03:38:28 PM]] Step 1375: train 0.482291 lr: 7.498e-04\n","[[06/14/2021 03:39:17 PM]] Step 1400: train 0.470411 lr: 7.366e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 03:40:02 PM]] Snapshot loss 0.611229\n","[[06/14/2021 03:40:02 PM]] This performance:0.611229 is not as a good as our previously saved:0.588879\n","[[06/14/2021 03:40:02 PM]] ====================Epoch 15====================\n","[[06/14/2021 03:40:54 PM]] Step 1425: train 0.464638 lr: 7.234e-04\n","[[06/14/2021 03:41:46 PM]] Step 1450: train 0.457675 lr: 7.102e-04\n","[[06/14/2021 03:42:38 PM]] Step 1475: train 0.451771 lr: 6.971e-04\n","[[06/14/2021 03:43:33 PM]] Step 1500: train 0.441920 lr: 6.839e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.35s/it]\n","[[06/14/2021 03:44:18 PM]] Snapshot loss 0.622324\n","[[06/14/2021 03:44:18 PM]] This performance:0.622324 is not as a good as our previously saved:0.588879\n","[[06/14/2021 03:44:18 PM]] ====================Epoch 16====================\n","[[06/14/2021 03:45:09 PM]] Step 1525: train 0.435838 lr: 6.707e-04\n","[[06/14/2021 03:45:59 PM]] Step 1550: train 0.430832 lr: 6.575e-04\n","[[06/14/2021 03:46:53 PM]] Step 1575: train 0.424566 lr: 6.443e-04\n","[[06/14/2021 03:47:49 PM]] Step 1600: train 0.418918 lr: 6.311e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 03:48:34 PM]] Snapshot loss 0.607692\n","[[06/14/2021 03:48:34 PM]] This performance:0.607692 is not as a good as our previously saved:0.588879\n","[[06/14/2021 03:48:34 PM]] ====================Epoch 17====================\n","[[06/14/2021 03:49:22 PM]] Step 1625: train 0.413091 lr: 6.179e-04\n","[[06/14/2021 03:50:15 PM]] Step 1650: train 0.406493 lr: 6.047e-04\n","[[06/14/2021 03:51:14 PM]] Step 1675: train 0.400788 lr: 5.915e-04\n","[[06/14/2021 03:52:06 PM]] Step 1700: train 0.397216 lr: 5.783e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.34s/it]\n","[[06/14/2021 03:52:51 PM]] Snapshot loss 0.594142\n","[[06/14/2021 03:52:52 PM]] This performance:0.594142 is not as a good as our previously saved:0.588879\n","[[06/14/2021 03:52:52 PM]] ====================Epoch 18====================\n","[[06/14/2021 03:53:47 PM]] Step 1725: train 0.393128 lr: 5.651e-04\n","[[06/14/2021 03:54:40 PM]] Step 1750: train 0.389238 lr: 5.519e-04\n","[[06/14/2021 03:55:30 PM]] Step 1775: train 0.391007 lr: 5.387e-04\n","[[06/14/2021 03:56:18 PM]] Step 1800: train 0.383579 lr: 5.255e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 03:57:04 PM]] Snapshot loss 0.632387\n","[[06/14/2021 03:57:04 PM]] This performance:0.632387 is not as a good as our previously saved:0.588879\n","[[06/14/2021 03:57:04 PM]] ====================Epoch 19====================\n","[[06/14/2021 03:57:55 PM]] Step 1825: train 0.381530 lr: 5.123e-04\n","[[06/14/2021 03:58:45 PM]] Step 1850: train 0.379978 lr: 4.991e-04\n","[[06/14/2021 03:59:39 PM]] Step 1875: train 0.376004 lr: 4.859e-04\n","[[06/14/2021 04:00:35 PM]] Step 1900: train 0.371506 lr: 4.727e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.35s/it]\n","[[06/14/2021 04:01:20 PM]] Snapshot loss 0.629507\n","[[06/14/2021 04:01:20 PM]] This performance:0.629507 is not as a good as our previously saved:0.588879\n","[[06/14/2021 04:01:20 PM]] ====================Epoch 20====================\n","[[06/14/2021 04:02:14 PM]] Step 1925: train 0.365845 lr: 4.596e-04\n","[[06/14/2021 04:03:02 PM]] Step 1950: train 0.364250 lr: 4.464e-04\n","[[06/14/2021 04:03:56 PM]] Step 1975: train 0.358743 lr: 4.332e-04\n","[[06/14/2021 04:04:50 PM]] Step 2000: train 0.358667 lr: 4.200e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 04:05:36 PM]] Snapshot loss 0.627771\n","[[06/14/2021 04:05:36 PM]] This performance:0.627771 is not as a good as our previously saved:0.588879\n","[[06/14/2021 04:05:36 PM]] ====================Epoch 21====================\n","[[06/14/2021 04:06:26 PM]] Step 2025: train 0.356589 lr: 4.068e-04\n","[[06/14/2021 04:07:17 PM]] Step 2050: train 0.357285 lr: 3.936e-04\n","[[06/14/2021 04:08:10 PM]] Step 2075: train 0.351058 lr: 3.804e-04\n","[[06/14/2021 04:09:04 PM]] Step 2100: train 0.350376 lr: 3.672e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.37s/it]\n","[[06/14/2021 04:09:50 PM]] Snapshot loss 0.603482\n","[[06/14/2021 04:09:50 PM]] This performance:0.603482 is not as a good as our previously saved:0.588879\n","[[06/14/2021 04:09:50 PM]] ====================Epoch 22====================\n","[[06/14/2021 04:10:40 PM]] Step 2125: train 0.344822 lr: 3.540e-04\n","[[06/14/2021 04:11:34 PM]] Step 2150: train 0.337493 lr: 3.408e-04\n","[[06/14/2021 04:12:26 PM]] Step 2175: train 0.333839 lr: 3.276e-04\n","[[06/14/2021 04:13:17 PM]] Step 2200: train 0.326942 lr: 3.144e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.38s/it]\n","[[06/14/2021 04:14:02 PM]] Snapshot loss 0.614080\n","[[06/14/2021 04:14:02 PM]] This performance:0.614080 is not as a good as our previously saved:0.588879\n","[[06/14/2021 04:14:02 PM]] ====================Epoch 23====================\n","[[06/14/2021 04:14:58 PM]] Step 2225: train 0.323473 lr: 3.012e-04\n","[[06/14/2021 04:15:52 PM]] Step 2250: train 0.317642 lr: 2.880e-04\n","[[06/14/2021 04:16:43 PM]] Step 2275: train 0.318774 lr: 2.748e-04\n","[[06/14/2021 04:17:35 PM]] Step 2300: train 0.314631 lr: 2.616e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.37s/it]\n","[[06/14/2021 04:18:21 PM]] Snapshot loss 0.619439\n","[[06/14/2021 04:18:21 PM]] This performance:0.619439 is not as a good as our previously saved:0.588879\n","[[06/14/2021 04:18:21 PM]] ====================Epoch 24====================\n","[[06/14/2021 04:19:12 PM]] Step 2325: train 0.307752 lr: 2.484e-04\n","[[06/14/2021 04:20:04 PM]] Step 2350: train 0.295962 lr: 2.352e-04\n","[[06/14/2021 04:20:56 PM]] Step 2375: train 0.288181 lr: 2.221e-04\n","[[06/14/2021 04:21:49 PM]] Step 2400: train 0.284528 lr: 2.089e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.35s/it]\n","[[06/14/2021 04:22:34 PM]] Snapshot loss 0.603404\n","[[06/14/2021 04:22:34 PM]] This performance:0.603404 is not as a good as our previously saved:0.588879\n","[[06/14/2021 04:22:34 PM]] ====================Epoch 25====================\n","[[06/14/2021 04:23:26 PM]] Step 2425: train 0.288332 lr: 1.957e-04\n","[[06/14/2021 04:24:20 PM]] Step 2450: train 0.286084 lr: 1.825e-04\n","[[06/14/2021 04:25:13 PM]] Step 2475: train 0.277092 lr: 1.693e-04\n","[[06/14/2021 04:26:03 PM]] Step 2500: train 0.279697 lr: 1.561e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.36s/it]\n","[[06/14/2021 04:26:48 PM]] Snapshot loss 0.602332\n","[[06/14/2021 04:26:48 PM]] This performance:0.602332 is not as a good as our previously saved:0.588879\n","[[06/14/2021 04:26:48 PM]] ====================Epoch 26====================\n","[[06/14/2021 04:27:39 PM]] Step 2525: train 0.275252 lr: 1.429e-04\n","[[06/14/2021 04:28:33 PM]] Step 2550: train 0.272485 lr: 1.297e-04\n","[[06/14/2021 04:29:25 PM]] Step 2575: train 0.266277 lr: 1.165e-04\n","[[06/14/2021 04:30:17 PM]] Step 2600: train 0.262297 lr: 1.033e-04\n","100%|██████████| 4/4 [00:45<00:00, 11.35s/it]\n","[[06/14/2021 04:31:03 PM]] Snapshot loss 0.599074\n","[[06/14/2021 04:31:03 PM]] This performance:0.599074 is not as a good as our previously saved:0.588879\n","[[06/14/2021 04:31:03 PM]] ====================Epoch 27====================\n","[[06/14/2021 04:31:52 PM]] Step 2625: train 0.263208 lr: 9.011e-05\n","[[06/14/2021 04:32:45 PM]] Step 2650: train 0.262183 lr: 7.692e-05\n","[[06/14/2021 04:33:36 PM]] Step 2675: train 0.260473 lr: 6.372e-05\n","[[06/14/2021 04:34:33 PM]] Step 2700: train 0.256209 lr: 5.053e-05\n","100%|██████████| 4/4 [00:45<00:00, 11.35s/it]\n","[[06/14/2021 04:35:18 PM]] Snapshot loss 0.604875\n","[[06/14/2021 04:35:18 PM]] This performance:0.604875 is not as a good as our previously saved:0.588879\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9mbyxIdXfYy5","executionInfo":{"status":"ok","timestamp":1623688578224,"user_tz":-180,"elapsed":5162,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["torch.save(model.state_dict(), './model.pth')"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ndmPlUHfa2O","executionInfo":{"status":"ok","timestamp":1623688580726,"user_tz":-180,"elapsed":353,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}}},"source":["# Predict function\n","def predict(loader, *, return_y=False):\n","    model.eval()\n","    outputs, y_global = [], []\n","    with torch.set_grad_enabled(False):\n","        for input_tensors in loader:\n","            input_tensors = [x.to(model.device) for x in input_tensors if x is not None]\n","            outputs.append(bot.predict_batch(input_tensors).cpu())\n","        outputs = torch.cat(outputs, dim=0)\n","    return outputs"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kAe1W6U_kzPl"},"source":["# Predict"]},{"cell_type":"code","metadata":{"id":"ORIble07fbR4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623689426621,"user_tz":-180,"elapsed":843345,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"0aa16df6-11fe-4e33-d915-5a6ea8113d88"},"source":["preds = predict(test_loader)\n","len(preds)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12359"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"4_yLk1L0ff5b","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1623689582592,"user_tz":-180,"elapsed":535,"user":{"displayName":"Girya_Is_BacK_WOT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC6gFZ5r-v1rksGX6gU2xD2T9tj-u0jXhq9uWMWQ=s64","userId":"09477952267509107267"}},"outputId":"661554f8-0397-4245-881f-fe000277b992"},"source":["df_sub = pd.DataFrame(torch.softmax(preds, -1).cpu().numpy().clip(1e-3, 1-1e-3), columns=[\"A\", \"B\", \"NEITHER\"])\n","df_sub[\"ID\"] = df_test.ID\n","df_sub.head()"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>NEITHER</th>\n","      <th>ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.710140</td>\n","      <td>0.281646</td>\n","      <td>0.008214</td>\n","      <td>000075809a8e6b062f5fb3c191a8ed52</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.990411</td>\n","      <td>0.002958</td>\n","      <td>0.006631</td>\n","      <td>0005d0f3b0a6c9ffbd31a48453029911</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.060085</td>\n","      <td>0.864929</td>\n","      <td>0.074986</td>\n","      <td>0007775c40bedd4147a0573d66dc28f8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.472420</td>\n","      <td>0.524444</td>\n","      <td>0.003135</td>\n","      <td>001194e3fe1234d00198ef6bba4cc588</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.066665</td>\n","      <td>0.927180</td>\n","      <td>0.006154</td>\n","      <td>0014bb7085278ef3f9b74f14771caca9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          A         B   NEITHER                                ID\n","0  0.710140  0.281646  0.008214  000075809a8e6b062f5fb3c191a8ed52\n","1  0.990411  0.002958  0.006631  0005d0f3b0a6c9ffbd31a48453029911\n","2  0.060085  0.864929  0.074986  0007775c40bedd4147a0573d66dc28f8\n","3  0.472420  0.524444  0.003135  001194e3fe1234d00198ef6bba4cc588\n","4  0.066665  0.927180  0.006154  0014bb7085278ef3f9b74f14771caca9"]},"metadata":{"tags":[]},"execution_count":32}]}]}